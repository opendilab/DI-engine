

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DataLoader Overview &mdash; DI-engine 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="开发者指南" href="../guide/index_zh.html" />
    <link rel="prev" title="Loader模块介绍" href="loader_overview_zh.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index_zh.html" class="icon icon-home"> DI-engine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">使用者指南</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index_zh.html">安装说明</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index_zh.html">快速上手</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index_zh.html">强化学习基础概念介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hands_on/index_zh.html">强化学习算法攻略合集</a></li>
<li class="toctree-l1"><a class="reference internal" href="../env_tutorial/index_zh.html">强化学习环境示例手册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed/index_zh.html">分布式</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index_zh.html">最佳实践</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index_zh.html">FAQ</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index_zh.html">特性介绍</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="algorithm_overview_zh.html">Algorithm Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="env_overview_zh.html">Env Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="collector_overview_zh.html">Collector Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="env_manager_overview_zh.html">Env Manager Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="learner_overview_zh.html">Learner Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="wrapper_hook_overview_zh.html">Wrapper &amp; Hook Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="hpc_rl_overview_zh.html">HPC_RL Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="interaction_overview_zh.html">Interaction模块介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="autolog_overview_zh.html">Autolog模块介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="loader_overview_zh.html">Loader模块介绍</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">DataLoader Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#profile-experiment">Profile Experiment 测速实验</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">开发者指南</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index_zh.html">开发者指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../specification/index_zh.html">中间件（middleware）编写规范</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index_zh.html">DI-engine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index_zh.html">Docs</a> &raquo;</li>
        
          <li><a href="index_zh.html">特性介绍</a> &raquo;</li>
        
      <li>DataLoader Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/feature/dataloader_overview_zh.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dataloader-overview">
<h1>DataLoader Overview<a class="headerlink" href="#dataloader-overview" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<dl>
<dt>概述：</dt><dd><p>参照 PyTorch 中的 DataLoader ，我们结合 <strong>从硬盘读取训练数据至内存</strong> 的实际需求，设计了 <strong>异步式数据加载器</strong> 。</p>
<p>AsyncDataLoader 支持将训练数据读取任务分割为多个子任务交由 <strong>多进程</strong> 执行，大大缩短了 I/O 时间。</p>
<dl class="simple">
<dt>AsyncDataLoader 包含以下进程或线程：</dt><dd><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">get_data_thread</span></code> 线程：获取数据读取任务，并将其发送给 <code class="docutils literal notranslate"><span class="pre">async_process</span></code> 进程。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cuda_thread</span></code> 线程：若指定需要 GPU 数据，则在该线程中将数据从 CPU 搬运至 GPU。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">async_process</span></code> 进程：若 num_workers=0，则该进程负责执行所有的数据读取任务；否则，将数据读取任务根据 <code class="docutils literal notranslate"><span class="pre">chunk_size</span></code> 分为多个子任务，并放置在 <code class="docutils literal notranslate"><span class="pre">job_queue</span></code> 中。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">worker</span></code> 进程列表：包含多个 worker 进程，每个 worker 进程都从 <code class="docutils literal notranslate"><span class="pre">job_queue</span></code> 中获取数据读取任务并执行。</p></li>
</ul>
</dd>
</dl>
</dd>
<dt>数据加载流程：</dt><dd><div class="admonition note">
<p class="admonition-title">Note</p>
<p>AsyncDataLoader 是异步加载数据的，即同一时刻各进程、线程均在工作。
以下流程可以理解为一条数据从磁盘文件到 learner 端用于训练之间所经历的过程。</p>
</div>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">async_process</span></code> 通过管道向 <code class="docutils literal notranslate"><span class="pre">get_data_thread</span></code> 发送“获取数据”请求，进入流程2。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_data_thread</span></code> 从 <code class="docutils literal notranslate"><span class="pre">data_source</span></code> 处获取到数据或数据任务。若为数据，则直接放置在 <code class="docutils literal notranslate"><span class="pre">async_train_queue</span></code> （该情况并不主要讨论，也并非 AsyncDataLoader 的设计初衷），直接进入流程5；否则将其通过管道发回给 <code class="docutils literal notranslate"><span class="pre">async_process</span></code> ，进入流程3。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">async_process</span></code> 判断 <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> 的大小：若为0或1表明不使用多进程（ <code class="docutils literal notranslate"><span class="pre">__init__</span></code> 中 <code class="docutils literal notranslate"><span class="pre">worker</span></code> 进程列表也不会被初始化），直接在本进程中读取数据，并将读取到的数据放置在 <code class="docutils literal notranslate"><span class="pre">async_train_queue</span></code> ，直接进入流程5；若为大于1的数则表明使用多进程，本进程仅负责将数据读取任务切分成 <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> / <code class="docutils literal notranslate"><span class="pre">chunk_size</span></code> 块，并放置在 <code class="docutils literal notranslate"><span class="pre">job_queue</span></code> 中，进入流程4。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">worker</span></code> 进程列表中的每一个元素 <code class="docutils literal notranslate"><span class="pre">worker_process</span></code> 从 <code class="docutils literal notranslate"><span class="pre">job_queue</span></code> 中获取一个数据读取任务并执行，读出的数据按照原来的 batch 进行存储及连接。由于 需要保证batch 之间的顺序，所以只有当上一个 batch 的数据全部被读出，上一个 batch 的数据放入 <code class="docutils literal notranslate"><span class="pre">async_train_queue</span></code> 后，才可以将下一个 batch 的数据放入 <code class="docutils literal notranslate"><span class="pre">async_train_queue</span></code> ，否则即使数据读取连接完毕，也必须等待。然后进入流程5.</p></li>
<li><p>若指定需要 GPU 数据，则 <code class="docutils literal notranslate"><span class="pre">cuda_thread</span></code> 将 <code class="docutils literal notranslate"><span class="pre">async_train_queue</span></code> 中的数据从 CPU 搬运至 GPU，并存储在 <code class="docutils literal notranslate"><span class="pre">cuda_queue</span></code> 。</p></li>
</ol>
</dd>
</dl>
</div>
<div class="section" id="profile-experiment">
<h2>Profile Experiment 测速实验<a class="headerlink" href="#profile-experiment" title="Permalink to this headline">¶</a></h2>
<p>我们将 AsyncDataLoader 与 PyTorch 中的 DataLoader （以下简称 TorchDataLoader ）进行了速度上的对比。结果表明，在各种规模的环境下、以及各种数据流压力下， AsyncDataLoader 都比 TorchDataLoader 有较明显的效率优势，且随着环境规模与数据流压力的增大，优势更加明显。</p>
<ul>
<li><p>实验准备</p>
<blockquote>
<div><p>我们准备了四个规模不同的环境，轨迹数据文件大小也各不相同：</p>
<blockquote>
<div><ul class="simple">
<li><p>Small Env (4.5KB)，Atari’s Pong 规模</p></li>
<li><p>Middle Env (40KB)</p></li>
<li><p>Big16 Env (16MB)</p></li>
<li><p>Big64 Env (64MB)，星际规模</p></li>
</ul>
</div></blockquote>
<p>环境相应参数如下表：</p>
<blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 31%" />
<col style="width: 17%" />
<col style="width: 18%" />
<col style="width: 18%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>File Time</p></th>
<th class="head"><p>Process Time</p></th>
<th class="head"><p>Batch Size</p></th>
<th class="head"><p>Chunk Size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Small Env</p></td>
<td><p>0.0008</p></td>
<td><p>0.005</p></td>
<td><p>128</p></td>
<td><p>32</p></td>
</tr>
<tr class="row-odd"><td><p>Middle Env</p></td>
<td><p>0.0008</p></td>
<td><p>0.05</p></td>
<td><p>64</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even"><td><p>Big16 Env</p></td>
<td><p>0.6</p></td>
<td><p>0.2</p></td>
<td><p>4</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Big64 Env</p></td>
<td><p>2</p></td>
<td><p>0.35</p></td>
<td><p>4</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>其中，File Time 指将数据从文件中读取到内存的时间， Process Time 指数据预处理时间，这两个时间均为多次重复实验测得。Batch Size 为一批数据数量， Chunk Size 为将一批数据分割开后的一块数据数量，是 AsyncDataLoader 的一个参数。</p>
</div></blockquote>
<p>我们还设定了三个 数据处理（ DataLoader 读取并预处理数据）时间 / 数据推断（模型利用数据）时间 这一比例，用于模拟 DataLoader 的不同工作负载；也可以理解为，当数据不变时，网络规模递减（意味着数据推断时间递减）时， DataLoader 应对越来越密集的数据需求的能力。
分别为：</p>
<blockquote>
<div><ul class="simple">
<li><p>Slow Dataflow, ratio=1.</p></li>
<li><p>Middle Dataflow, ratio=2.</p></li>
<li><p>Fast Dataflow, ratio=3.</p></li>
</ul>
</div></blockquote>
<p>一次实验包括50次数据处理+推断过程，即50次迭代，忽略前5次时间表现不太稳定的迭代，取后45次的平均值作为单次实验结果。实验重复10次取平均值。
实验中 <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> 设为8，使用GPU进行数据推断。</p>
</div></blockquote>
</li>
<li><p>实验结果</p>
<blockquote>
<div><p>我们测量了三种 DataLoader ，分别是：</p>
<blockquote>
<div><ul class="simple">
<li><p>TorchDataLoader, num_workers=0，即不使用多进程，以作为baseline。以下简称 TorchDataLoader-base</p></li>
<li><p>TorchDataLoader, num_workers=8，即和 AsyncDataLoader 使用相同的进程数。以下简称 TorchDataLoader-8</p></li>
<li><p>我们实现的 AsyncDataLoader</p></li>
</ul>
</div></blockquote>
<p>也将按照从上至下的顺序展示三个 DataLoader 的测速结果。</p>
<p>首先是整体流程所用全部时间（单位：秒）：</p>
<blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 32%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Slow Dataflow</p></th>
<th class="head"><p>Middle Dataflow</p></th>
<th class="head"><p>Fast Dataflow</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="3"><p>Small Env</p></td>
<td><p>36.62</p></td>
<td><p>34.00</p></td>
<td><p>32.82</p></td>
</tr>
<tr class="row-odd"><td><p>5.41</p></td>
<td><p>4.52</p></td>
<td><p>4.26</p></td>
</tr>
<tr class="row-even"><td><p>4.36</p></td>
<td><p>4.49</p></td>
<td><p>4.15</p></td>
</tr>
<tr class="row-odd"><td rowspan="3"><p>Middle Env</p></td>
<td><p>162.40</p></td>
<td><p>153.50</p></td>
<td><p>149.20</p></td>
</tr>
<tr class="row-even"><td><p>19.36</p></td>
<td><p>18.64</p></td>
<td><p>19.05</p></td>
</tr>
<tr class="row-odd"><td><p>18.80</p></td>
<td><p>18.51</p></td>
<td><p>18.39</p></td>
</tr>
<tr class="row-even"><td rowspan="3"><p>Big16 Env</p></td>
<td><p>136.60</p></td>
<td><p>126.49</p></td>
<td><p>123.81</p></td>
</tr>
<tr class="row-odd"><td><p>20.39</p></td>
<td><p>19.59</p></td>
<td><p>20.35</p></td>
</tr>
<tr class="row-even"><td><p>18.76</p></td>
<td><p>9.26</p></td>
<td><p>7.70</p></td>
</tr>
<tr class="row-odd"><td rowspan="3"><p>Big64 Env</p></td>
<td><p>329.31</p></td>
<td><p>296.80</p></td>
<td><p>276.32</p></td>
</tr>
<tr class="row-even"><td><p>72.17</p></td>
<td><p>67.58</p></td>
<td><p>70.11</p></td>
</tr>
<tr class="row-odd"><td><p>52.13</p></td>
<td><p>26.01</p></td>
<td><p>19.56</p></td>
</tr>
</tbody>
</table>
<p>（注：由于逐渐增大的数据流压力是通过逐渐降低的 infer time 实现的，所以对于同一环境，数据流压力增大，总用时反而会减小）</p>
</div></blockquote>
<p>然后是在整体流程中，阻塞在 DataLoader ，等待其读取数据、处理数据的时间，所占整体时间的比例：</p>
<blockquote>
<div><table class="docutils align-default">
<colgroup>
<col style="width: 32%" />
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Slow Dataflow</p></th>
<th class="head"><p>Middle Dataflow</p></th>
<th class="head"><p>Fast Dataflow</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td rowspan="3"><p>Small Env</p></td>
<td><p>0.8825</p></td>
<td><p>0.9365</p></td>
<td><p>0.9670</p></td>
</tr>
<tr class="row-odd"><td><p>0.2044</p></td>
<td><p>0.5219</p></td>
<td><p>0.7403</p></td>
</tr>
<tr class="row-even"><td><p>0.0067</p></td>
<td><p>0.5087</p></td>
<td><p>0.7335</p></td>
</tr>
<tr class="row-odd"><td rowspan="3"><p>Middle Env</p></td>
<td><p>0.8843</p></td>
<td><p>0.9381</p></td>
<td><p>0.9684</p></td>
</tr>
<tr class="row-even"><td><p>0.0295</p></td>
<td><p>0.4955</p></td>
<td><p>0.7530</p></td>
</tr>
<tr class="row-odd"><td><p>0.0001</p></td>
<td><p>0.4923</p></td>
<td><p>0.7441</p></td>
</tr>
<tr class="row-even"><td rowspan="3"><p>Big16 Env</p></td>
<td><p>0.8645</p></td>
<td><p>0.9268</p></td>
<td><p>0.9625</p></td>
</tr>
<tr class="row-odd"><td><p>0.0927</p></td>
<td><p>0.5274</p></td>
<td><p>0.7703</p></td>
</tr>
<tr class="row-even"><td><p>0.0001</p></td>
<td><p>0.0008</p></td>
<td><p>0.3982</p></td>
</tr>
<tr class="row-odd"><td rowspan="3"><p>Big64 Env</p></td>
<td><p>0.8421</p></td>
<td><p>0.9124</p></td>
<td><p>0.9525</p></td>
</tr>
<tr class="row-even"><td><p>0.2796</p></td>
<td><p>0.6127</p></td>
<td><p>0.8142</p></td>
</tr>
<tr class="row-odd"><td><p>0.0000</p></td>
<td><p>0.0001</p></td>
<td><p>0.3350</p></td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>不难发现，三者的数据读取速度及整体训练效率为： AsyncDataLoader &gt; TorchDataLoader-8 &gt; TorchDataLoader-base。
且 <strong>当环境规模增大，或是数据流压力增大时， AsyncDataLoader 的优势更加明显</strong> 。</p>
<p>我们还观察了在 Big64 Env 中， Fast Dataflow 情况下的 <strong>CPU负载</strong> 。我们发现 AsyncDataLoader 确实是提高了 CPU 负载才获得了如此优秀的性能提升： CPU 负载约为 60%，接近 TorchDataLoader-8 的 CPU 负载率20%的三倍，这一点也与其相较于 TorchDataLoader-8 27%的训练时间相吻合。
同时我们还发现， AsyncDataLoader 的 CPU 负载相对稳定，在60%附近小幅波动；而 TorchDataLoader-8 随时间波动非常大，低至1%，高至50%。</p>
</div></blockquote>
</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../guide/index_zh.html" class="btn btn-neutral float-right" title="开发者指南" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="loader_overview_zh.html" class="btn btn-neutral float-left" title="Loader模块介绍" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab Contributors

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>