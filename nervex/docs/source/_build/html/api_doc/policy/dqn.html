

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>DQN &mdash; nerveX 0.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Rainbow" href="rainbow.html" />
    <link rel="prev" title="Policy" href="index.html" />
    <link href="../../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> nerveX
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hands_on/index.html">Hands on RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">API Doc</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../config/index.html">Config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../env/index.html">Env</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Policy</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">DQN</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dqnpolicy">DQNPolicy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="rainbow.html">Rainbow</a></li>
<li class="toctree-l3"><a class="reference internal" href="r2d2.html">R2D2</a></li>
<li class="toctree-l3"><a class="reference internal" href="a2c.html">A2C</a></li>
<li class="toctree-l3"><a class="reference internal" href="ddpg.html">DDPG</a></li>
<li class="toctree-l3"><a class="reference internal" href="qmix.html">QMIX</a></li>
<li class="toctree-l3"><a class="reference internal" href="coma.html">COMA</a></li>
<li class="toctree-l3"><a class="reference internal" href="collaq.html">CollaQ</a></li>
<li class="toctree-l3"><a class="reference internal" href="ppg.html">PPG</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../model/index.html">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reward_model/index.html">Reward Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../league/index.html">League</a></li>
<li class="toctree-l2"><a class="reference internal" href="../worker/replay_buffer/index.html">Buffer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../torch_utils/index.html">Torch Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../utils/index.html">Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../interaction/index.html">Interaction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../feature/index.html">Feature</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../supplementary_rl/index.html">Supplementary of RL</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial_dev/index.html">Tutorial-Developer</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">nerveX</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">API Doc</a> &raquo;</li>
        
          <li><a href="index.html">Policy</a> &raquo;</li>
        
      <li>DQN</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/api_doc/policy/dqn.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dqn">
<h1>DQN<a class="headerlink" href="#dqn" title="Permalink to this headline">¶</a></h1>
<div class="section" id="dqnpolicy">
<h2>DQNPolicy<a class="headerlink" href="#dqnpolicy" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="nervex.policy.dqn.DQNPolicy">
<em class="property">class </em><code class="sig-prename descclassname">nervex.policy.dqn.</code><code class="sig-name descname">DQNPolicy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">cfg</span><span class="p">:</span> <span class="n">dict</span></em>, <em class="sig-param"><span class="n">model</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>Union<span class="p">[</span>type<span class="p">, </span>torch.nn.modules.module.Module<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em>, <em class="sig-param"><span class="n">enable_field</span><span class="p">:</span> <span class="n">Optional<span class="p">[</span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span></span> <span class="o">=</span> <span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DQN algorithm, extended by Double DQN/Dueling DQN/PER/multi-step TD.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<colgroup>
<col style="width: 2%" />
<col style="width: 19%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 37%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><ol class="arabic simple" start="4">
<li></li>
</ol>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">may be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>1,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">this args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._forward_collect">
<code class="sig-name descname">_forward_collect</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>int<span class="p">, </span>Any<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">eps</span><span class="p">:</span> <span class="n">float</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>Any<span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._forward_collect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._forward_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of collect mode(collect training data), with eps_greedy for exploration.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
<li><p>eps (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>): epsilon value for exploration, which is decayed by collected env step.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting policy_output(action) for the interaction with                 env and the constructing of transition.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">logit</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._forward_eval">
<code class="sig-name descname">_forward_eval</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>int<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>int<span class="p">, </span>Any<span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._forward_eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._forward_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of eval mode(evaluate policy performance), at most cases, it is similar to             <code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, stacked env data for predicting policy_output(action),                 values are torch.Tensor or np.ndarray or dict/list combinations, keys are env_id indicated by integer.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[int,</span> <span class="pre">Any]</span></code>): The dict of predicting action for the interaction with env.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">action</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._forward_learn">
<code class="sig-name descname">_forward_learn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._forward_learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._forward_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward computation graph of learn mode(updating policy).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a batch of data for training, values are torch.Tensor or                 np.ndarray or dict/list combinations.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>info_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): Dict type data, a info dict indicated training result, which will be                 recorded in text log and tensorboard, values are python scalar or a list of scalars.</p></li>
</ul>
</dd>
<dt>ArgumentsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">next_obs</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">value_gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">IS</span></code></p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>necessary: <code class="docutils literal notranslate"><span class="pre">cur_lr</span></code>, <code class="docutils literal notranslate"><span class="pre">total_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">priority</span></code></p></li>
<li><p>optional: <code class="docutils literal notranslate"><span class="pre">action_distribution</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._get_train_sample">
<code class="sig-name descname">_get_train_sample</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span><span class="p">:</span> <span class="n">List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; List<span class="p">[</span>Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._get_train_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._get_train_sample" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>For a given trajectory(transitions, a list of transition) data, process it into a list of sample that             can be used for training directly. A train sample can be a processed transition(DQN with nstep TD)             or some continuous transitions(DRQN).</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>data (<code class="xref py py-obj docutils literal notranslate"><span class="pre">List[Dict[str,</span> <span class="pre">Any]</span></code>): The trajectory data(a list of transition), each element is the same                 format as the return value of <code class="docutils literal notranslate"><span class="pre">self._process_transition</span></code> method.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>samples (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): The list of training samples.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We will vectorize <code class="docutils literal notranslate"><span class="pre">process_transition</span></code> and <code class="docutils literal notranslate"><span class="pre">get_train_sample</span></code> method in the following release version.             And the user can customize the this data processing procecure by overriding this two methods and collector             itself.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._init_collect">
<code class="sig-name descname">_init_collect</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._init_collect"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._init_collect" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Collect mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize algorithm arguments and collect_model,             enable the eps_greedy_sample for exploration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._init_eval">
<code class="sig-name descname">_init_eval</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._init_eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._init_eval" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Evaluate mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize eval_model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._init_learn">
<code class="sig-name descname">_init_learn</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._init_learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._init_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Learn mode init method. Called by <code class="docutils literal notranslate"><span class="pre">self.__init__</span></code>, initialize the optimizer, algorithm arguments, main             and target model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._load_state_dict_learn">
<code class="sig-name descname">_load_state_dict_learn</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">state_dict</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._load_state_dict_learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._load_state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Load the state_dict variable into policy learn mode.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of policy learn state saved before.</p></li>
</ul>
</dd>
</dl>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you want to only load some parts of model, you can simply set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument in             load_state_dict to <code class="docutils literal notranslate"><span class="pre">False</span></code>, or refer to <code class="docutils literal notranslate"><span class="pre">nervex.torch_utils.checkpoint_helper</span></code> for more             complicated operation.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._process_transition">
<code class="sig-name descname">_process_transition</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">obs</span><span class="p">:</span> <span class="n">Any</span></em>, <em class="sig-param"><span class="n">policy_output</span><span class="p">:</span> <span class="n">Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span></span></em>, <em class="sig-param"><span class="n">timestep</span><span class="p">:</span> <span class="n">collections.namedtuple</span></em><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._process_transition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._process_transition" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Generate a transition(e.g.: &lt;s, a, <a href="#id1"><span class="problematic" id="id2">s_</span></a>, r, d) for this algorithm training.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Any</span></code>): Env observation.</p></li>
<li><p>policy_output (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): The output of policy collect mode(<code class="docutils literal notranslate"><span class="pre">self._forward_collect</span></code>),                including at least <code class="docutils literal notranslate"><span class="pre">action</span></code>.</p></li>
<li><p>timestep (<code class="xref py py-obj docutils literal notranslate"><span class="pre">namedtuple</span></code>): The output after env step(execute policy output action), including at                 least <code class="docutils literal notranslate"><span class="pre">obs</span></code>, <code class="docutils literal notranslate"><span class="pre">reward</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code>, (here obs indicates obs after env step).</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>transition (<code class="xref py py-obj docutils literal notranslate"><span class="pre">dict</span></code>): Dict type transition data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy._state_dict_learn">
<code class="sig-name descname">_state_dict_learn</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Dict<span class="p">[</span>str<span class="p">, </span>Any<span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy._state_dict_learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy._state_dict_learn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the state_dict of learn mode, usually including model and optimizer.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>state_dict (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict[str,</span> <span class="pre">Any]</span></code>): the dict of current policy learn state, for saving and restoring.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nervex.policy.dqn.DQNPolicy.default_model">
<code class="sig-name descname">default_model</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple<span class="p">[</span>str<span class="p">, </span>List<span class="p">[</span>str<span class="p">]</span><span class="p">]</span><a class="reference internal" href="../../_modules/nervex/policy/dqn.html#DQNPolicy.default_model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nervex.policy.dqn.DQNPolicy.default_model" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return this algorithm default model setting for demostration.</p>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>model_info (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Tuple[str,</span> <span class="pre">List[str]]</span></code>): model name and mode import_names</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The user can define and use customized network model but must obey the same inferface definition indicated             by import_names path. For DQN, <code class="docutils literal notranslate"><span class="pre">nervex.model.template.q_learning.DQN</span></code></p>
</div>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="rainbow.html" class="btn btn-neutral float-right" title="Rainbow" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="index.html" class="btn btn-neutral float-left" title="Policy" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, X-Lab.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>