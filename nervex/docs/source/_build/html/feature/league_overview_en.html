

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>League Overview &mdash; nerveX 0.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="HPC_RL Overview" href="hpc_rl_overview_en.html" />
    <link rel="prev" title="Wrapper &amp; Hook Overview" href="wrapper_hook_overview_en.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nerveX
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hands_on/index.html">Hands on RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Feature</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="algorithm_overview.html">Algorithm Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="policy_overview_en.html">Policy Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="model_overview_en.html">Model Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="env_overview_en.html">Env Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="collector_overview_en.html">Collector Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="env_manager_overview_en.html">Env Manager Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="replay_buffer_overview_en.html">Replay Buffer Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="learner_overview.html">Learner Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="wrapper_hook_overview_en.html">Wrapper &amp; Hook Overview</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">League Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#league-intro">League Intro</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nervex-implementation">nerveX Implementation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#player">Player</a></li>
<li class="toctree-l4"><a class="reference internal" href="#payoff">Payoff</a></li>
<li class="toctree-l4"><a class="reference internal" href="#league">League</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hpc_rl_overview_en.html">HPC_RL Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataloader_overview.html">DataLoader Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="autolog_overview.html">Autolog Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="interaction_overview_en.html">Interaction Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="loader_overview_en.html">Loader Overview</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../supplementary_rl/index.html">Supplementary of RL</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nerveX</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Feature</a> &raquo;</li>
        
      <li>League Overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/feature/league_overview_en.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="league-overview">
<h1>League Overview<a class="headerlink" href="#league-overview" title="Permalink to this headline">¶</a></h1>
<dl>
<dt>Abstract:</dt><dd><p>The concept of League training is from <a class="reference external" href="../rl_warmup/algorithm/large-scale-rl.html#alphastar">AlphaStar</a>.
League training is a multi-agent reinforcement learning algorithm that is designed both to address the cycles commonly
encountered during self-play training and to integrate a diverse range of strategies. In the league of AlphaStar, there exists
different types of agent as league members that differ only in the distribution of opponent they train against. In nerveX,
we call these members player. Each player holds a strategy, i.e. neural networks or rules.</p>
<p>In 1v1 RTS games like StarCraft2, the league is responsible for assigning opponents to players.
Different players can fight each other and generate very rich game data to update their own strategies. This is one of the most important
components to make AlphaStar successfully.</p>
<p>In the following paragraphs, We’ll first introduce the training pipline of League, then there will be a brief summary of the implementation
of <code class="docutils literal notranslate"><span class="pre">league</span></code> module in nerveX.</p>
</dd>
</dl>
<div class="section" id="league-intro">
<h2>League Intro<a class="headerlink" href="#league-intro" title="Permalink to this headline">¶</a></h2>
<p>In 1v1 competitive games, we always hope to find two players with similar levels. In this way the trajectory generated is more meaningful
for strategy optimization. The navie implementation is self-play, which means agents plays with itself to upate its strategy.</p>
<p>In self-play, a problem that is worth taking note of is whether the opponent is exactly the same as the agent itself, with updatable strategies
and parameters, or it is the strategies periodically frozen from the best parameters at that time.</p>
<blockquote>
<div><ul class="simple">
<li><p>In the first case, two identical players play against each other, and the generated trajectory data can be put into the same replay buffer for the learner to sample data and optimize the strategy. In this case, double the training data will be generated. But at the same time, this becomes a 2-agent problem, and once the number of agents in the environment exceeds one, the interaction process is no longer a Markov process, and the stability of the optimization process will be far less than that of a single agent.</p></li>
<li><p>In the latter case, the player will freeze a current best strategy every certain number of iterations, and use this frozen player as the opponent in the next stage. It is expected that after each stage, the player will become stronger. At this time, only the non-frozen player generated trajectory can be used for training. In this case, there will be a problem similar to “rock-paper-scissors”: the player is first trained as the best strategy A, then be trained as strategy B after freezing and defeats strategy A, and be trained as strategy C after freezing and defeats strategy B again. Strategy C will lose to strategy A finally.</p></li>
</ul>
</div></blockquote>
<p>To alleviate these problems, the training pipline of self-play is usually implemented as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Initialize an empty player pool, then put the first player in it.</p></li>
<li><p>At this time, the pool has only one player, only the first approach is possible.</p></li>
<li><p>After a certain number of iterations, the current player is frozen to a snapshot, and the snapshot player is added to the player pool.</p></li>
<li><p>According to certain rules, league chooses one player from the pool as the opponent, then both the first and the second approach can be used.</p></li>
<li><p>When the updatable strategy is good enough, the training process ends.</p></li>
</ol>
</div></blockquote>
<p>The nerveX’s demo of league <code class="docutils literal notranslate"><span class="pre">app_zoo/competitive_rl/entry/cpong_dqn_default_config.py</span></code> is implemented as the above process.</p>
<p>AlphaStar uses a more complicated league training algorithm than self-play, and designs more types of players differ in the distribution of opponent
they train against. The “Rock-paper-scissors” problem can be alleviated in this way, also the strategy will be more diverse. More details can be found
in the AlphaStar paper’s “Methods - MultiAgent Learning” part.</p>
</div>
<div class="section" id="nervex-implementation">
<h2>nerveX Implementation<a class="headerlink" href="#nervex-implementation" title="Permalink to this headline">¶</a></h2>
<p>NerveX’s implementation of league consists of three parts:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Player</span></code>：Player is the participant of game, consists of active (i.e. updatable) and historical (i.e. unupdatable) player.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Payoff</span></code>：Payoff is used to record the results of game play in league. This module is shared by all players, can be the references of to choose opponents.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">League</span></code>：league holds all of the players and payoff records, responsible for maintaining payoff and player status, and assigning opponents to players based on payoff.</p></li>
</ul>
</div></blockquote>
<div class="section" id="player">
<h3>Player<a class="headerlink" href="#player" title="Permalink to this headline">¶</a></h3>
<dl>
<dt>Abstract:</dt><dd><p>Player is the memeber of the league, also the participant of the competitive games. Each player holds a share of parameters or rules, which means it act in an unique strategy.</p>
<p>Player consists of active player and historical player:</p>
<blockquote>
<div><ul class="simple">
<li><p>Active means player’s model is updatable. In most cases these are the players in the league which need training.</p></li>
<li><p>Historical means player’s model is frozen from the past active player, used as the opponent of active player, to enrich the diversity of data.</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
<p>Code Structure:</p>
<blockquote>
<div><p>The main classes are as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Player</span></code>: Base class of player, holds most properties.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ActivePlayer</span></code>: Updatable player, can be assigned opponents to play in league. After training for a period of time, historical player can be generated through snapshot of ActivePlayer.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HistoricalPlayer</span></code>: Unupdatable player, can be acquired by loading a pretrained model or snapshot from active player.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NaiveSpPlayer</span></code>: An self play version implementation of active player, can be used to play with historical player or itself.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MainPlayer</span></code>: A special implementation of active player, used in AlphaStar. More details can be found in AlphaStar paper.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MainExploiter</span></code>: A special implementation of active player, used in AlphaStar. More details can be found in AlphaStar paper.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LeagueExploiter</span></code>: A special implementation of active player, used in AlphaStar. More details can be found in AlphaStar paper.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
<dl>
<dt>Base Class Definition：</dt><dd><ol class="arabic">
<li><p>Player (nervex/league/player.py)</p>
<blockquote>
<div><ul>
<li><p>Abstract:</p>
<blockquote>
<div><p>Base class player defines properties needed by both active player and historical player, including catagory, payoff, checkpoint path, id,
training iteration, etc. Player is an abstract base class and cannot be instantiated.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p>HistoricalPlayer (nervex/league/player.py)</p>
<blockquote>
<div><ul>
<li><p>Abstract:</p>
<blockquote>
<div><p>HistoricalPlayer defines parent id additionally comparing to player class.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p>ActivePlayer (nervex/league/player.py)</p>
<blockquote>
<div><ul>
<li><p>Abstract:</p>
<blockquote>
<div><p>League will assign opponents of active player by its <code class="docutils literal notranslate"><span class="pre">get_job</span></code> method When it is called by commander to generate new collect job.
After collector starting to execute tasks, learner use the generated data train itself. After some iterations, learner will call league by commander,
then league use corresponding player’s <code class="docutils literal notranslate"><span class="pre">is_trained_enough</span></code> method to judge whether the policy of collector is trained enough. If so, call <code class="docutils literal notranslate"><span class="pre">snapshot</span></code>
or <code class="docutils literal notranslate"><span class="pre">mutate</span></code> to get a snapshot historical player or reset to specific parameters.</p>
</div></blockquote>
</li>
<li><dl class="simple">
<dt>API：</dt><dd><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>: For initialization.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_trained_enough</span></code>: To judge whether this player is trained enough by training steps.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">snapshot</span></code>: Freeze the network parameters, create a historical player and return.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mutate</span></code>: Mutate the model, e.g. resetting to a specific parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_job</span></code>: Get game play job. To call cooresponding player’s <code class="docutils literal notranslate"><span class="pre">_get_collect_opponent</span></code> method to get opponent.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Methods need to override by users：</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">ActivePlayer</span></code> don’t implement specific methods to select opponent. The example of selecting opponent can be like <code class="docutils literal notranslate"><span class="pre">NaiveSpPlayer</span></code>: 50% to naive self play,
50% to select historical players randomly. To archive this, nerveX needs to modify player class and config:</p>
<ol class="arabic">
<li><p>config</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in nervex/config/league.py</span>
<span class="n">naive_sp_player</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="c1"># ...</span>
    <span class="n">branch_probs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">pfsp</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">sp</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">NaiveSpPlayer</span></code></p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NaiveSpPlayer</span><span class="p">(</span><span class="n">ActivePlayer</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_pfsp_branch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">HistoricalPlayer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_opponent</span><span class="p">(</span><span class="n">historical</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sp_branch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ActivePlayer</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ol>
<p>The class hierarchy of player can be shown as follows：</p>
<blockquote>
<div><img alt="../_images/league_player_img.png" class="align-center" src="../_images/league_player_img.png" />
</div></blockquote>
</dd>
</dl>
</div>
<div class="section" id="payoff">
<h3>Payoff<a class="headerlink" href="#payoff" title="Permalink to this headline">¶</a></h3>
<p>Abstract:</p>
<blockquote>
<div><p>Payoff is used to record historical game play results, as the reference of assigning opponents. E.g. In competitive games, payoff can be used to
calculate the winrate between two players.</p>
</div></blockquote>
<p>Code Structure:</p>
<blockquote>
<div><p>Payoff contains two components:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BattleRecordDict</span></code>: Succeed from dict, recording game play results between every two players. Initialized to all four keys [‘wins’, ‘draws’, ‘losses’, ‘games’] to 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BattleSharedPayoff</span></code>: Use <code class="docutils literal notranslate"><span class="pre">BattleRecordDict</span></code> to record specific two player’s game play records, calculate winrate of them.</p></li>
</ol>
</div></blockquote>
</div></blockquote>
</div>
<div class="section" id="league">
<h3>League<a class="headerlink" href="#league" title="Permalink to this headline">¶</a></h3>
<p>Abstract:</p>
<blockquote>
<div><p>league is the class to manage players and their relationship(i.e. payoff), as a property of commander. Commander call league’s <code class="docutils literal notranslate"><span class="pre">get_job_info</span></code> method
to collect task for two players to play a round of game.</p>
</div></blockquote>
<dl>
<dt>Base Class Definition：</dt><dd><ol class="arabic">
<li><p>BaseLeague (nervex/league/base_league.py)</p>
<blockquote>
<div><ul>
<li><p>Abstract:</p>
<blockquote>
<div><p>League follow the commands of commander to provide useful information of game plays for commander.</p>
</div></blockquote>
</li>
<li><dl class="simple">
<dt>API:</dt><dd><ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>: Initialization, call <code class="docutils literal notranslate"><span class="pre">_init_cfg</span></code> first to read config of league, then call <code class="docutils literal notranslate"><span class="pre">_init_league</span></code> to initialize league players.cfg``.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_job_info</span></code>:  When commander assigns job to collector, call this method to get which two players to execute this job.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">judge_snapshot</span></code>: After learner use generated data to update its strategy, the corresponding player’s strategy will be updated. After training for some time, commander calls this method to judge whether the model is trained enough.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">update_active_player</span></code>: After Learner updated or evaluator evaluated, update cooresponding player’s train stpe or choose opponent for next evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">finish_job</span></code>: When collector task finished, update game play information in shared payoff.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Methods need to override by users：</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">_get_job_info</span></code>: called by <code class="docutils literal notranslate"><span class="pre">_launch_job</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_mutate_player</span></code>: called by <code class="docutils literal notranslate"><span class="pre">_snapshot</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_update_player</span></code>: called by <code class="docutils literal notranslate"><span class="pre">update_active_player</span></code>. All three methods above are abstract method, refer to  <code class="docutils literal notranslate"><span class="pre">nervex/league/one_vs_one_league.py</span></code> <code class="docutils literal notranslate"><span class="pre">OneVsOneLeague</span></code> for more implementation details.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ol>
</dd>
</dl>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="hpc_rl_overview_en.html" class="btn btn-neutral float-right" title="HPC_RL Overview" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="wrapper_hook_overview_en.html" class="btn btn-neutral float-left" title="Wrapper &amp; Hook Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, X-Lab.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>