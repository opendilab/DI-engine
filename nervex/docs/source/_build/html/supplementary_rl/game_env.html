

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>强化学习常用的游戏环境/RL Game Environments &mdash; nerveX 0.2.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Bandit" href="bandit/index.html" />
    <link rel="prev" title="RL Exploration" href="algorithm/rl-exploration.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nerveX
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start/index.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../key_concept/index.html">Key Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_rl/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hands_on/index.html">Hands on RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature/index.html">Feature</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Supplementary of RL</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="algorithm/index.html">算法与训练/Algorithm and Training</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">强化学习常用的游戏环境/RL Game Environments</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">科研论文中常用的基础环境</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#openai-gym">OpenAI gym</a></li>
<li class="toctree-l4"><a class="reference internal" href="#openai-gym-retro">OpenAI gym retro</a></li>
<li class="toctree-l4"><a class="reference internal" href="#gridworldminigrid">Gridworld、MiniGrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multiagent-particle">Multiagent Particle</a></li>
<li class="toctree-l4"><a class="reference internal" href="#procgen">ProcGen</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#python">已有训练相关python接口的中型游戏环境</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#malmo">Malmo</a></li>
<li class="toctree-l4"><a class="reference internal" href="#obstacle-tower">Obstacle Tower</a></li>
<li class="toctree-l4"><a class="reference internal" href="#torcs">Torcs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#deepmind-lab">DeepMind Lab</a></li>
<li class="toctree-l4"><a class="reference internal" href="#vizdoom">VizDoom</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pommerman">Pommerman</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quake-iii-arena-capture-the-flag">Quake III Arena Capture the Flag</a></li>
<li class="toctree-l4"><a class="reference internal" href="#google-research-football">Google Research Football</a></li>
<li class="toctree-l4"><a class="reference internal" href="#neural-mmos">Neural MMOs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fever-basketball">Fever Basketball</a></li>
<li class="toctree-l4"><a class="reference internal" href="#smac">SMAC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bandit/index.html">Bandit</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guide/index.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial_dev/index.html">Tutorial-Developer</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nerveX</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Supplementary of RL</a> &raquo;</li>
        
      <li>强化学习常用的游戏环境/RL Game Environments</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/supplementary_rl/game_env.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="rl-game-environments">
<h1>强化学习常用的游戏环境/RL Game Environments<a class="headerlink" href="#rl-game-environments" title="Permalink to this headline">¶</a></h1>
<p>对强化学习中常见的游戏环境做一些介绍，对于在科研论文中常用的小型环境（Atari等）只做简单介绍，主要概述一些中型的游戏环境。</p>
<div class="section" id="id1">
<h2>科研论文中常用的基础环境<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="openai-gym">
<h3>OpenAI gym<a class="headerlink" href="#openai-gym" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>gym是强化学习论文实验中最常见的环境，包含<strong>Atari游戏、Classic
Control、Mujuco控制等</strong>。</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip3 install gym

pip3 install atari-py

pip3 install mujuco_py

pip install box2d-py

<span class="c1">#  or</span>

git clone https://github.com/openai/gym.git

<span class="nb">cd</span> gym

pip3 install -e <span class="s1">&#39;.[all]&#39;</span>
</pre></div>
</div>
<p>使用：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;envname&#39;</span><span class="p">)</span>
<span class="n">ob</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">ob</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
</pre></div>
</div>
<p>其中，Mujuco环境的使用需要在官网license认证，也可用pybullet作替代。</p>
</div>
<div class="section" id="openai-gym-retro">
<h3><a class="reference external" href="https://github.com/openai/retro">OpenAI gym retro</a><a class="headerlink" href="#openai-gym-retro" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>OpenAI在gym的基础上加入了更多的游戏接入，集成为Retro。在Atari之外，还支持任天堂和世嘉的一些游戏。一个经典的案例是OpenAI在2018年举办的<a class="reference external" href="https://openai.com/blog/retro-contest/">Sonic游戏迁移学习比赛</a>，便是建立在Retro环境上。支持的游戏列表如下：</p>
<ul class="simple">
<li><p>Atari</p>
<ul>
<li><p>Atari2600 (via Stella)</p></li>
</ul>
</li>
<li><p>NEC</p>
<ul>
<li><p>TurboGrafx-16/PC Engine (via Mednafen/Beetle PCE Fast)</p></li>
</ul>
</li>
<li><p>Nintendo</p>
<ul>
<li><p>Game Boy/Game Boy Color (via gambatte)</p></li>
<li><p>Game Boy Advance (via mGBA)</p></li>
<li><p>Nintendo Entertainment System (via FCEUmm)</p></li>
<li><p>Super Nintendo Entertainment System (via Snes9x)</p></li>
</ul>
</li>
<li><p>Sega</p>
<ul>
<li><p>GameGear (via Genesis Plus GX)</p></li>
<li><p>Genesis/Mega Drive (via Genesis Plus GX)</p></li>
<li><p>Master System (via Genesis Plus GX)</p></li>
</ul>
</li>
</ul>
<p>由于涉及到游戏版权问题，retro只提供了无需商业授权的ROM用于游戏测试和智能体训练。列表如下：</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.pouet.net/prod.php?which=2762">the 128 sine-dot</a> by
Anthrox</p></li>
<li><p><a class="reference external" href="https://pdroms.de/files/gamegear/sega-tween">Sega Tween</a> by Ben
Ryves</p></li>
<li><p><a class="reference external" href="http://www.pouet.net/prod.php?which=52716">Happy 10!</a> by Blind IO</p></li>
<li><p><a class="reference external" href="https://pdroms.de/files/pcengine/512-colour-test-demo">512-Colour Test
Demo</a> by
Chris Covell</p></li>
<li><p><a class="reference external" href="http://www.pouet.net/prod.php?which=67142">Dekadrive</a> by
Dekadence</p></li>
<li><p><a class="reference external" href="https://pdroms.de/files/atari2600/automaton-minigame-compo-2003">Automaton</a>
by Derek Ledbetter</p></li>
<li><p><a class="reference external" href="http://privat.bahnhof.se/wb800787/gb/demo/64/">Fire</a> by dox</p></li>
<li><p><a class="reference external" href="http://www.pouet.net/prod.php?which=53497">FamiCON intro</a> by dr88</p></li>
<li><p><a class="reference external" href="https://pdroms.de/genesis/airstriker-v1-50-genesis-game">Airstriker</a>
by Electrokinesis</p></li>
<li><p><a class="reference external" href="https://pdroms.de/files/gameboyadvance/lost-marbles">Lost
Marbles</a> by
Vantage</p></li>
</ul>
<p>其余游戏均需要自行下载ROM使用，可在<a class="reference external" href="https://archive.org/details/No-Intro-Collection_2016-01-03_Fixed">Archive.org</a>下载，导入方式如下：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">retro</span><span class="o">.</span><span class="kn">import</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">your</span><span class="o">/</span><span class="n">ROMs</span><span class="o">/</span><span class="n">directory</span><span class="o">/</span>
</pre></div>
</div>
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip3</span> <span class="n">install</span> <span class="n">gym</span><span class="o">-</span><span class="n">retro</span>
</pre></div>
</div>
<p>使用：</p>
<p>与openAI gym的接口保持一致。</p>
</div>
<div class="section" id="gridworldminigrid">
<h3><a class="reference external" href="https://github.com/Bigpig4396/Multi-Agent-Reinforcement-Learning-Environment">Gridworld</a>、<a class="reference external" href="https://github.com/maximecb/gym-minigrid">MiniGrid</a><a class="headerlink" href="#gridworldminigrid" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>GridWorld和MiniGrid两个都是强化学习中讨论探索利用问题和多智能体问题常用的环境，即二维走迷宫探索环境，实现简单，且容易修改定制地图本身和目标任务。其中，Gridworld的部分环境支持多智能体环境，MiniGrid只有单智能体相关的环境。</p>
<img alt="" src="../_images/GridWorld.png" />
<img alt="" src="../_images/MiniGrid.png" />
<p><strong>接口</strong></p>
<p>安装：</p>
<p>GridWorld未提交pip包管理服务器，需要git到本地目录导入。</p>
<p>MiniGrid直接通过<code class="docutils literal notranslate"><span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">gym-minigrid</span></code>安装。</p>
<p>使用：</p>
<p>与openAI gym保持一致。</p>
</div>
<div class="section" id="multiagent-particle">
<h3><a class="reference external" href="https://github.com/openai/multiagent-particle-envs">Multiagent Particle</a><a class="headerlink" href="#multiagent-particle" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>在nerveX中已有实现。Particle为OpenAI为研究多智能体之间的合作、竞争、通讯开发的强化学习环境，智能体的数量和目标任务都可以自定义设置，可以创建超大量级的协作粒子数，本身为MADDPG论文使用的环境。与之类似的还有UCL汪军团队开发的<a class="reference external" href="https://github.com/geek-ai/MAgent">MAgent</a>环境。</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<p>均需要到连接中git源码，对于Particle：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -e .
</pre></div>
</div>
<p>对于MAgent：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>bash build.sh
</pre></div>
</div>
<p>使用：</p>
<p>与openAI gym保持一致。</p>
</div>
<div class="section" id="procgen">
<h3><a class="reference external" href="https://openai.com/blog/procgen-benchmark/">ProcGen</a><a class="headerlink" href="#procgen" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>在nerveX中已有实现。ProcGen是OpenAI开发的用于验证强化学习模型迁移和泛化能力的环境。包含16个不同类型的小游戏，每款游戏都有相似类型的不同地图，用于验证模型的知识迁移能力。（官方有PPO算法下200M的训练，有收敛保证）</p>
<img alt="" src="../_images/ProcGen.png" />
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip3 install procgen
</pre></div>
</div>
<p>使用：</p>
<p>与openAI gym保持一致。</p>
</div>
</div>
<div class="section" id="python">
<h2>已有训练相关python接口的中型游戏环境<a class="headerlink" href="#python" title="Permalink to this headline">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>环境名称</p></th>
<th class="head"><p>游戏类型</p></th>
<th class="head"><p>状态空间</p></th>
<th class="head"><p>动作空间</p></th>
<th class="head"><p>奖励</p></th>
<th class="head"><p>备注</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Malmo</p></td>
<td><p>沙盒</p></td>
<td><p>图像</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>稀疏，
在挖到钻
石时获得</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Obstacle
Tower</p></td>
<td><p>解谜</p></td>
<td><p>图像</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>有游戏内
的dense
评价分数</p></td>
<td><p>Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-even"><td><p>Torcs</p></td>
<td><p>赛车</p></td>
<td><p>图
像或连续
的车路信
息vector</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>通常
根据任务
自行设计</p></td>
<td><p>Transfer
Learning</p></td>
</tr>
<tr class="row-odd"><td><p>DeepMind
Lab</p></td>
<td></td>
<td><p>图像</p></td>
<td><p>离散的
键盘映射</p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>VizDoom</p></td>
<td><p>FPS</p></td>
<td><p>图像和状
态vector</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>通常会
自行设计
（拾取、
击败等）</p></td>
<td><p>Sparse
Reward,
Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-odd"><td><p>P
ommerman</p></td>
<td><p>休闲</p></td>
<td><p>地
图特征ve
ctor及状
态vector</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>稀疏奖
励，在击
败时获得</p></td>
<td><p>POMDP,
Sparse
Reward,
Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-even"><td><p>Quake
III</p></td>
<td><p>FPS</p></td>
<td><p>图像</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>稀疏奖励
，在预定
时间拥有
Flag获得</p></td>
<td><p>Mul
tiAgent,
Sparse
Reward,
Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-odd"><td><p>Google
Research
Football</p></td>
<td><p>体育</p></td>
<td><p>图像或
连续的状
态vector</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>稀疏
奖励，进
球时获得</p></td>
<td><p>Mul
tiAgent,
Sparse
Reward</p></td>
</tr>
<tr class="row-even"><td><p>Neural
MMOs</p></td>
<td><p>MMORPG</p></td>
<td><p>图像</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>生存时
间，通常
根据任务
自行设计</p></td>
<td><p>Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-odd"><td><p>Fever
Ba
sketball</p></td>
<td><p>体育</p></td>
<td><p>ve
ctor信息</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>稀疏
奖励，得
分时获得</p></td>
<td><p>Sparse
Reward,
Exp
loration
&amp;
Expl
oitation</p></td>
</tr>
<tr class="row-even"><td><p>SMAC</p></td>
<td><p>RTS</p></td>
<td><p>ve
ctor信息</p></td>
<td><p>离散的
键盘映射</p></td>
<td><p>系数奖励
，胜利方
+1，负方
-1。也内
置了带有
击杀奖励
的设置。</p></td>
<td><p>Sparse
Reward,
Multi
Agent</p></td>
</tr>
</tbody>
</table>
<div class="section" id="malmo">
<h3><a class="reference external" href="https://github.com/Microsoft/malmo">Malmo</a><a class="headerlink" href="#malmo" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>Malmo是微软基于Minecraft开发的AI研究环境，本质上还是一个开放世界的环境，本身不涉及特定的任务。但可以在其上建立相对应的环境来实现任务设计，例如微软在17年在Malmo环境上做过合作抓猪的比赛，20年做了挖矿比赛。环境本身有和Java的Minecraft客户端直接通讯实现的版本，和python
based的版本。与java通讯的版本可以使用较大量的原生Minecraft实例，但与gym
API的不匹配情况也比较严重，纯python的版本可用的实例较少，但对于强化学习算法兼容性更好，且不需要编译java端的代码。</p>
<p>状态空间：图像RGB</p>
<p>动作空间：离散，对应键盘映射</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<p>在win10，Linux和MacOS均可以安装。按照<a class="reference external" href="https://github.com/Microsoft/malmo/blob/master/scripts/python-wheel/README.md">此链接</a>在各个平台上安装。几个重要的依赖项：</p>
<ul class="simple">
<li><p>Java8 JDK（需将JAVA_HOME加入环境变量）</p></li>
<li><p>git</p></li>
<li><p>ffmpeg</p></li>
</ul>
<p>也可以通过docker直接构建</p>
</div>
<div class="section" id="obstacle-tower">
<h3><a class="reference external" href="https://github.com/Unity-Technologies/obstacle-tower-env">Obstacle Tower</a><a class="headerlink" href="#obstacle-tower" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>基于Unity实现的一个类似三维魔塔的爬楼+解谜游戏。在AAAI
2020上被推出，并附有gym
interface。控制的状态空间为图像，动作空间为离散，包括WSAD方向，KL左右转视角和Space跳跃七维。（官方有使用Rainbow的训练实现）</p>
<img alt="" src="../_images/ObstacleTower.png" />
<p>状态空间：图像</p>
<p>动作空间：离散，对应键盘映射</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<ul class="simple">
<li><p>下载<a class="reference external" href="https://github.com/Unity-Technologies/obstacle-tower-env#download-the-environment-optional">游戏渲染程序</a>；</p></li>
<li><p>git python工程源码并安装依赖项；</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone git@github.com:Unity-Technologies/obstacle-tower-env.git
<span class="nb">cd</span> obstacle-tower-env
pip install -e .
</pre></div>
</div>
<ul class="simple">
<li><p>将游戏程序的ObstacleTower文件夹复制到python工程目录下即可。</p></li>
</ul>
<p><strong>使用</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">obstacle_tower_env</span> <span class="kn">import</span> <span class="n">ObstacleTowerEnv</span><span class="p">,</span> <span class="n">ObstacleTowerEvaluation</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">ObstacleTowerEnv</span><span class="p">(</span><span class="s2">&quot;./ObstacleTower/obstacletower&quot;</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">ObstacleTowerEvaluation</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">seeds</span><span class="p">)</span>
</pre></div>
</div>
<p>其余部分使用方式与openAI gym保持一致。</p>
</div>
<div class="section" id="torcs">
<h3><a class="reference external" href="https://link.zhihu.com/?target=https%3A//github.com/ugo-nama-kun/gym_torcs">Torcs</a><a class="headerlink" href="#torcs" title="Permalink to this headline">¶</a></h3>
<p>Torcs是一个RL领域比较出名的赛车环境。环境的输入为与现实情况比较接近的路侧距离等传感器信息或者图像信息，车辆本身的各项指标也都可定义，也提供了不同的地图供训练尝试。（官方有DDPG实现）</p>
<img alt="" src="../_images/Torcs.png" />
<p>状态空间：连续的车路信息vector或图像</p>
<p>动作空间：离散，对应键盘映射</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<p>仅在ubuntu环境下适用，需要安装依赖：</p>
<ul class="simple">
<li><p><a class="reference external" href="http://linux.die.net/man/7/xautomation">xautomation</a></p></li>
<li><p>gym</p></li>
<li><p><a class="reference external" href="https://github.com/giuse/vtorcs/tree/nosegfault">vtorcs-RL-color</a></p></li>
</ul>
<p>特别的，如果不需要处理RGB，在ubuntu上只需要：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo apt-get install xautomation
</pre></div>
</div>
<p>然后安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip3 install gym_torcs
</pre></div>
</div>
<p>需要渲染时，在不同平台需要安装对应的torcs软件。</p>
<p>使用：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gym_torcs</span> <span class="kn">import</span> <span class="n">TorcsEnv</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">TorcsEnv</span><span class="p">(</span><span class="n">vision</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">throttle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ob</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">relaunch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># with torcs relaunch (avoid memory leak bug in torcs)</span>
<span class="kn">from</span> <span class="nn">sample_agent</span> <span class="kn">import</span> <span class="n">Agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># steering only</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">ob</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">vision</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ob</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>
</pre></div>
</div>
<p>基本与OpenAI gym保持一致。</p>
</div>
<div class="section" id="deepmind-lab">
<span id="deepmind-lab-hard-eight"></span><h3><a class="reference external" href="https://github.com/deepmind/lab">DeepMind Lab</a><a class="headerlink" href="#deepmind-lab" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>DeepMind Lab是DeepMind在IMPALA论文中使用的环境，为3D导航探索任务。</p>
<img alt="" src="../_images/DeepMindLab.png" />
<p>在官方github上都提供了简单的python接口安装方式。</p>
</div>
<div class="section" id="vizdoom">
<h3><a class="reference external" href="https://github.com/mwydmuch/ViZDoom">VizDoom</a><a class="headerlink" href="#vizdoom" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>VizDoom是一个经典的FPS游戏，也是在RL里做过比赛的游戏环境。游戏本身可以使用不同武器（从地图中收集获取），目标是生存并击败对手。仿真速度很快（7000FPS，通常的游戏节奏~30FPS），对Win、Ubuntu和MacOS都可以支持，并支持自定义场景。</p>
<img alt="" src="../_images/VizDoom.png" />
<p>官方在16-18年举行了三届比赛，每次都是单人+多人死亡竞赛两条赛道。三年排名靠前的参赛者都是同一批人（Arnold、TSAIL和IntelAct），但游戏实际表现都未到达人类玩家的水平。TSAIL团队提供了其实现的一些细节，例如使用YOLO-v3作为检测框架来提取特征信息，并使用了分层强化学习的思路来训练agent。在<a class="reference external" href="https://ojs.aaai.org/index.php/AAAI/article/view/10827">AAAI2017的论文中</a>，也提到了在训练中采用目标检测框架来增加feature帮助RL算法的细节，其RL算法使用了DRQN。</p>
<p>状态空间：图像+状态vector。前者通常为30*45的图像，后者包含一些弹药情况、武器情况信息。</p>
<p>动作空间：离散，对应键盘映射。但也可以包含对应鼠标控制的连续量，通常将之离散化来操作。</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo apt install cmake libboost-all-dev libsdl2-dev libfreetype6-dev libgl1-mesa-dev libglu1-mesa-dev libpng-dev libjpeg-dev libbz2-dev libfluidsynth-dev libgme-dev libopenal-dev zlib1g-dev timidity tar nasm
pip install vizdoom
</pre></div>
</div>
<p>使用：</p>
<p>与openAI gym形式上相近，但细节稍有不同：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">vizdoom</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">game</span> <span class="o">=</span> <span class="n">DoomGame</span><span class="p">()</span>
<span class="n">game</span><span class="o">.</span><span class="n">load_config</span><span class="p">(</span><span class="s2">&quot;vizdoom/scenarios/basic.cfg&quot;</span><span class="p">)</span>
<span class="n">game</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="n">shoot</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">left</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">right</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="n">shoot</span><span class="p">,</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">]</span>

<span class="n">episodes</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
    <span class="n">game</span><span class="o">.</span><span class="n">new_episode</span><span class="p">()</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">game</span><span class="o">.</span><span class="n">is_episode_finished</span><span class="p">():</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">screen_buffer</span>
        <span class="n">misc</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">game_variables</span>
        <span class="n">reward</span> <span class="o">=</span> <span class="n">game</span><span class="o">.</span><span class="n">make_action</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">actions</span><span class="p">))</span>
        <span class="nb">print</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">reward:&quot;</span><span class="p">,</span> <span class="n">reward</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="nb">print</span> <span class="s2">&quot;Result:&quot;</span><span class="p">,</span> <span class="n">game</span><span class="o">.</span><span class="n">get_total_reward</span><span class="p">()</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>由于举办过VizDoom的比赛，因此相关的实例和一些算法的参考实现相对充足，可以参见<a class="reference external" href="http://vizdoom.cs.put.edu.pl/tutorial">tutorial</a>。</p>
</div>
<div class="section" id="pommerman">
<h3><a class="reference external" href="https://www.pommerman.com/">Pommerman</a><a class="headerlink" href="#pommerman" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>经典炸弹人小游戏，也是Nips2018竞赛的环境。涉及到了强化学习可能面对的探索利用、部分可观、多智能体和资源利用等多方面的问题。通常的版本为四个智能体，可以分别指定各个智能体使用的策略已进行自搏等训练。除了官方实现外，还有很多可以参考的a2c、ppo实现。</p>
<img alt="" src="../_images/Pommerman.png" />
<p>状态空间：地图特征vector及状态vector</p>
<ul class="simple">
<li><p><strong>Board:</strong> 121 Ints。agent 无法观测到的单位被标记为 5（迷雾）。</p></li>
<li><p><strong>Position:</strong> 2 Ints，大小 [0, 10]。agent 在游戏 Board 上的 (x, y)
位置坐标。</p></li>
<li><p><strong>Ammo:</strong> 1 Int。agent 当前可以使用的炸弹数量。</p></li>
<li><p><strong>Blast Strength:</strong> 1 Int.。agent 施放炸弹的爆炸范围。</p></li>
<li><p><strong>Can Kick:</strong> 1 Int，布尔变量。是否 agent 能踢炸弹。</p></li>
<li><p><strong>Teammate:</strong> 1 Int，范围 [-1, 3]. 当前 agent 的队友为哪个。</p></li>
<li><p><strong>Enemies:</strong> 3 Ints，范围 [-1, 3]。当前 agent 的敌人是哪些。如果是
2v2，那么第三个数值为 - 1。</p></li>
<li><p><strong>Bombs:</strong> List of Ints。agent 视野范围内的炸弹，通过三元数组表示（x
int, y int, blast_strength int），表示炸弹位置
x、y，以及炸弹爆炸范围。</p></li>
</ul>
<p>动作空间：离散，对应键盘映射</p>
<ul class="simple">
<li><p><strong>Stop:</strong> 静止不动</p></li>
<li><p><strong>Up:</strong> 向上走</p></li>
<li><p><strong>Left:</strong> 向左走</p></li>
<li><p><strong>Down:</strong> 向下走</p></li>
<li><p><strong>Right:</strong> 向右走</p></li>
<li><p><strong>Bomb:</strong> 放置一个炸弹</p></li>
</ul>
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/MultiAgentLearning/playground ~/playground
<span class="nb">cd</span> ~/playground
pip install -U .
</pre></div>
</div>
<p>使用：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pommerman</span>
<span class="kn">from</span> <span class="nn">pommerman</span> <span class="kn">import</span> <span class="n">agents</span>
<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">agent_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">agents</span><span class="o">.</span><span class="n">SimpleAgent</span><span class="p">(),</span>
        <span class="n">agents</span><span class="o">.</span><span class="n">RandomAgent</span><span class="p">(),</span>
        <span class="n">agents</span><span class="o">.</span><span class="n">SimpleAgent</span><span class="p">(),</span>
        <span class="n">agents</span><span class="o">.</span><span class="n">RandomAgent</span><span class="p">(),</span>
        <span class="c1"># agents.DockerAgent(&quot;pommerman/simple-agent&quot;, port=12345),</span>
    <span class="p">]</span>
    <span class="c1"># Make the &quot;Free-For-All&quot; environment using the agent list</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">pommerman</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;PommeFFACompetition-v0&#39;</span><span class="p">,</span> <span class="n">agent_list</span><span class="p">)</span>
    <span class="c1"># Run the episodes just like OpenAI Gym</span>
    <span class="k">for</span> <span class="n">i_episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
            <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
            <span class="n">actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
            <span class="n">state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Episode </span><span class="si">{}</span><span class="s1"> finished&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i_episode</span><span class="p">))</span>
    <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>与openAI gym类似，但由于是多智能体环境，需要指定每个智能体的策略。</p>
</div>
<div class="section" id="quake-iii-arena-capture-the-flag">
<h3><a class="reference external" href="https://github.com/deepmind/lab">Quake III Arena Capture the Flag</a><a class="headerlink" href="#quake-iii-arena-capture-the-flag" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>经典游戏雷神之锤夺旗竞技场地图，本身也是集成在DeepMind
Lab下的环境。游戏分为两队，每队有两个智能体，在不同的地图中以第一人称视角进行夺旗游戏。因为DeepMind在这个环境上做训练的成果发在了<a class="reference external" href="https://deepmind.com/blog/article/capture-the-flag-science">Science</a>上，因此比较出名。DeepMind在这里用了population
based的训练方法，在延迟0.26秒的反应时间前提下获得了超越人类玩家的智能体。训练框架仅在linux下可用。</p>
<img alt="" src="../_images/QuakeCTF.png" />
<p>状态空间：图像，大小可自定义</p>
<p>动作空间：本身为连续动作空间，但通常会进行离散化到键盘映射。固定为几个确定的动作模式。例如：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ACTIONS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;look_left&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="o">-</span><span class="mi">20</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;look_right&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;look_up&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;look_down&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;strafe_left&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;strafe_right&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;forward&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;backward&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;fire&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;jump&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
    <span class="s1">&#39;crouch&#39;</span><span class="p">:</span> <span class="n">_action</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
<p><strong>接口</strong></p>
<p>安装：</p>
<ul class="simple">
<li><p>安装<a class="reference external" href="https://docs.bazel.build/versions/master/install.html">bazel</a></p></li>
<li><p>git
Deepmind提供的python框架源码<code class="docutils literal notranslate"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://github.com/deepmind/lab</span></code></p></li>
<li><p>在<code class="docutils literal notranslate"><span class="pre">/lab/python/pip_package</span></code>中<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">-e</span> <span class="pre">.</span></code>安装相关依赖包</p></li>
</ul>
<p>使用：</p>
<p>提供了直接作为玩家接入的模式和智能体训练模式。对于后者，可以参考<a class="reference external" href="https://github.com/deepmind/lab/blob/master/python/random_agent.py">官方实例</a>。用法与上面的pommerman接近，需选定agent和env类型。</p>
</div>
<div class="section" id="google-research-football">
<h3><a class="reference external" href="https://github.com/google-research/football">Google Research Football</a><a class="headerlink" href="#google-research-football" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>这个环境是 google
基于之前某个足球小游戏的环境进行改动和封装出来的，主要可以分为 11v11
single-agent 场景（控制一个 active player 在 11 名球员中切换）和 5v5
multi-agent 场景（控制 4 名球员 + 1 个守门员）。该环境支持
self-play，有三种难度内置 AI 可以打。游戏状态基于 vector
的主要是球员的坐标 / 速度 / 角色 / 朝向 /
红黄牌等，也可以用图像输入，动作输出有二十多维，包括不同方向 / 长短传 /
加速等。是Google在Kaggle上举办过比赛的环境，实际会面对RL中的多智能体、稀疏奖励等多种问题。环境训练本身支持Linux和MacOS。</p>
<img alt="" src="../_images/GFootball.png" />
<p>状态空间：图像或vector信息</p>
<p>动作空间：离散，对应键盘映射</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>sudo apt-get install git cmake build-essential libgl1-mesa-dev libsdl2-dev <span class="se">\</span>
libsdl2-image-dev libsdl2-ttf-dev libsdl2-gfx-dev libboost-all-dev <span class="se">\</span>
libdirectfb-dev libst-dev mesa-utils xvfb x11vnc libsdl-sge-dev python3-pip
python3 -m pip install --upgrade pip setuptools psutil
python3 -m pip install gfootball
</pre></div>
</div>
<p>使用：</p>
<p>官方有内建的tensorflow实例，并使用openAI
baseline来训练。因此整个交互框架与openAI gym相同。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gfootball.env</span> <span class="k">as</span> <span class="nn">football_env</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">football_env</span><span class="o">.</span><span class="n">create_environment</span><span class="p">(</span><span class="n">env_name</span><span class="o">=</span><span class="s2">&quot;academy_empty_goal_close&quot;</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logdir</span><span class="o">=</span><span class="s1">&#39;/tmp/football&#39;</span><span class="p">,</span> <span class="n">write_goal_dumps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">write_full_episode_dumps</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">render</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
  <span class="n">obs</span><span class="p">,</span> <span class="n">rew</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
  <span class="n">steps</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">if</span> <span class="n">steps</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Step </span><span class="si">%d</span><span class="s2"> Reward: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">rew</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
    <span class="k">break</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Steps: </span><span class="si">%d</span><span class="s2"> Reward: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">rew</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="neural-mmos">
<h3><a class="reference external" href="https://github.com/openai/neural-mmo">Neural MMOs</a><a class="headerlink" href="#neural-mmos" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>OpenAI开源的大型MultiAgent环境，在非常大的地图中设定有限资源。也因为地图非常大，对IO开销非常大。</p>
<img alt="" src="../_images/NeuralMMOs.png" />
<p><strong>接口</strong></p>
<p>安装：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/jsuarez5341/neural-mmo-client
<span class="nb">cd</span> neural-mmo-client
bash setup.sh
<span class="nb">cd</span> ..

git clone https://github.com/openai/neural-mmo
<span class="nb">cd</span> neural-mmo
bash scripts/setup/setup.s
</pre></div>
</div>
<p>使用：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python Forge.py --render <span class="c1">#Run the environment with rendering on</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">forge.trinity</span> <span class="kn">import</span> <span class="n">smith</span>
<span class="n">envs</span> <span class="o">=</span> <span class="n">smith</span><span class="o">.</span><span class="n">VecEnv</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>

<span class="c1">#The environment is persistent: call reset only upon initialization</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1">#Observations contain entity and stimulus</span>
<span class="c1">#for each agent in each environment.</span>
<span class="n">actions</span> <span class="o">=</span> <span class="n">your_algorithm_here</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

<span class="c1">#The environment is persistent: &quot;dones&quot; is always None</span>
<span class="c1">#If an observation is missing, that agent has died</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">envs</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="fever-basketball">
<h3><a class="reference external" href="https://github.com/FuxiRL/FeverBasketball">Fever Basketball</a><a class="headerlink" href="#fever-basketball" title="Permalink to this headline">¶</a></h3>
<p><strong>简介</strong></p>
<p>网易伏羲开源的潮人篮球游戏，支持1v1，2v2，3v3环境，提供内置不同难度的AI，支持self-play。</p>
<img alt="" src="../_images/FeverBasketball.png" />
<p>状态空间：vector信息</p>
<p>动作空间：离散，对应键盘映射</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<ul class="simple">
<li><p>安装python工程文件。</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/FuxiRL/FeverBasketball.git
pip3 install -r requirements.txt
</pre></div>
</div>
<ul class="simple">
<li><p>下载<a class="reference external" href="https://pan.baidu.com/share/init?surl=visZLh5QEXqQakdVOlPqhg">游戏客户端</a></p></li>
</ul>
<p>使用：</p>
<p>环境并未用gym的形式进行封装，而是以socket通信的方式与windows客户端程序进行交互来实现step和observe。网易伏羲官方提供了几种RL算法包括PPO、QMIX等的实现（未调）。</p>
</div>
<div class="section" id="smac">
<h3><a class="reference external" href="https://github.com/canyon/smac">SMAC</a><a class="headerlink" href="#smac" title="Permalink to this headline">¶</a></h3>
<p>NerveX中已有实现。SMAC是调用星际争霸2接口实现的多智能体RL环境，游戏类型为RTS，基于星际争霸2的API和DeepMind的PySC2实现。在星际争霸2的常规完整游戏中，一个或多个人类彼此竞争或与内置游戏
AI 竞争，以收集资源，建造建筑物并建立部队单位以击败对手。SMAC
由一套完整星际争霸2的一小部分组成，旨在评估Agent学习协调解决复杂任务的能力。这些场景经过精心设计，必须学习一种或多种微操技术才能击败敌人。每种情况都是两支部队之间的对抗。每个部队的初始位置，数量和类型随场景的不同而变化。具体包括如下内容：</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Ally Units</p></th>
<th class="head"><p>Enemy Units</p></th>
<th class="head"><p>Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>3m</p></td>
<td><p>3 Marines</p></td>
<td><p>3 Marines</p></td>
<td><p>homogeneous &amp;
symmetric</p></td>
</tr>
<tr class="row-odd"><td><p>8m</p></td>
<td><p>8 Marines</p></td>
<td><p>8 Marines</p></td>
<td><p>homogeneous &amp;
symmetric</p></td>
</tr>
<tr class="row-even"><td><p>25m</p></td>
<td><p>25 Marines</p></td>
<td><p>25 Marines</p></td>
<td><p>homogeneous &amp;
symmetric</p></td>
</tr>
<tr class="row-odd"><td><p>2s3z</p></td>
<td><p>2 Stalkers &amp; 3
Zealots</p></td>
<td><p>2 Stalkers &amp; 3
Zealots</p></td>
<td><p>heterogeneous
&amp; symmetric</p></td>
</tr>
<tr class="row-even"><td><p>3s5z</p></td>
<td><p>3 Stalkers &amp; 5
Zealots</p></td>
<td><p>3 Stalkers &amp; 5
Zealots</p></td>
<td><p>heterogeneous
&amp; symmetric</p></td>
</tr>
<tr class="row-odd"><td><p>MMM</p></td>
<td><p>1 Medivac, 2
Marauders &amp; 7
Marines</p></td>
<td><p>1 Medivac, 2
Marauders &amp; 7
Marines</p></td>
<td><p>heterogeneous
&amp; symmetric</p></td>
</tr>
<tr class="row-even"><td><p>5m_vs_6m</p></td>
<td><p>5 Marines</p></td>
<td><p>6 Marines</p></td>
<td><p>homogeneous &amp;
asymmetric</p></td>
</tr>
<tr class="row-odd"><td><p>8m_vs_9m</p></td>
<td><p>8 Marines</p></td>
<td><p>9 Marines</p></td>
<td><p>homogeneous &amp;
asymmetric</p></td>
</tr>
<tr class="row-even"><td><p>10m_vs_11m</p></td>
<td><p>10 Marines</p></td>
<td><p>11 Marines</p></td>
<td><p>homogeneous &amp;
asymmetric</p></td>
</tr>
<tr class="row-odd"><td><p>27m_vs_30m</p></td>
<td><p>27 Marines</p></td>
<td><p>30 Marines</p></td>
<td><p>homogeneous &amp;
asymmetric</p></td>
</tr>
<tr class="row-even"><td><p>3s5z_vs_3s6z</p></td>
<td><p>3 Stalkers &amp; 5
Zealots</p></td>
<td><p>3 Stalkers &amp; 6
Zealots</p></td>
<td><p>heterogeneous
&amp; asymmetric</p></td>
</tr>
<tr class="row-odd"><td><p>MMM2</p></td>
<td><p>1 Medivac, 2
Marauders &amp; 7
Marines</p></td>
<td><p>1 Medivac, 3
Marauders &amp; 8
Marines</p></td>
<td><p>heterogeneous
&amp; asymmetric</p></td>
</tr>
<tr class="row-even"><td><p>2m_vs_1z</p></td>
<td><p>2 Marines</p></td>
<td><p>1 Zealot</p></td>
<td><p>micro-trick:
alternating
fire</p></td>
</tr>
<tr class="row-odd"><td><p>2s_vs_1sc</p></td>
<td><p>2 Stalkers</p></td>
<td><p>1 Spine
Crawler</p></td>
<td><p>micro-trick:
alternating
fire</p></td>
</tr>
<tr class="row-even"><td><p>3s_vs_3z</p></td>
<td><p>3 Stalkers</p></td>
<td><p>3 Zealots</p></td>
<td><p>micro-trick:
kiting</p></td>
</tr>
<tr class="row-odd"><td><p>3s_vs_4z</p></td>
<td><p>3 Stalkers</p></td>
<td><p>4 Zealots</p></td>
<td><p>micro-trick:
kiting</p></td>
</tr>
<tr class="row-even"><td><p>3s_vs_5z</p></td>
<td><p>3 Stalkers</p></td>
<td><p>5 Zealots</p></td>
<td><p>micro-trick:
kiting</p></td>
</tr>
<tr class="row-odd"><td><p>6h_vs_8z</p></td>
<td><p>6 Hydralisks</p></td>
<td><p>8 Zealots</p></td>
<td><p>micro-trick:
focus fire</p></td>
</tr>
<tr class="row-even"><td><p>corridor</p></td>
<td><p>6 Zealots</p></td>
<td><p>24 Zerglings</p></td>
<td><p>micro-trick:
wall off</p></td>
</tr>
<tr class="row-odd"><td><p>bane_vs_bane</p></td>
<td><p>20 Zerglings &amp;
4 Banelings</p></td>
<td><p>20 Zerglings &amp;
4 Banelings</p></td>
<td><p>micro-trick:
positioning</p></td>
</tr>
<tr class="row-even"><td><p>so_many
_banelings</p></td>
<td><p>7 Zealots</p></td>
<td><p>32 Banelings</p></td>
<td><p>micro-trick:
positioning</p></td>
</tr>
<tr class="row-odd"><td><p>2c_vs_64zg</p></td>
<td><p>2 Colossi</p></td>
<td><p>64 Zerglings</p></td>
<td><p>micro-trick:
positioning</p></td>
</tr>
</tbody>
</table>
<p>状态空间：vector信息，包括每个单位视野范围（9）内其它单位的信息，包括距离、相对位置、血量、单位类型等。</p>
<p>动作空间：离散。包括移动（向四个方向）、攻击（对于医疗单位为治疗）、停止和无操作，攻击（治疗）需选定视野范围内的目标。</p>
<p><strong>接口</strong></p>
<p>安装：</p>
<ul class="simple">
<li><p>安装<a class="reference external" href="https://github.com/canyon/smac#installing-starcraft-ii">StarCraft
II</a>（Linux，Win
or MacOS）。</p></li>
<li><p>安装python工程。</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">oxwhirl</span><span class="o">/</span><span class="n">smac</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
<p>使用：</p>
<p>沿用PySC2的接口。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># for testing</span>
<span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">smac</span><span class="o">.</span><span class="n">examples</span><span class="o">.</span><span class="n">random_agents</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="bandit/index.html" class="btn btn-neutral float-right" title="Bandit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="algorithm/rl-exploration.html" class="btn btn-neutral float-left" title="RL Exploration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, X-Lab.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>