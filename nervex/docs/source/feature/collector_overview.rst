Collector Overview
====================

Profile Experiment 测速实验
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

我们对 nerveX 中的 collector 进行了测速实验，测试其在不同规模的环境与不同类型的环境管理器下，收集一定量数据所需的时间，并与 tianshou 进行了对比。

**结果表明，nerveX collector 性能上整体优于 tianshou collector，且在大规模环境或长 reset time 环境中优势更加明显。**

- 实验准备

    我们准备了三个规模不同的环境，参数如下表：

        +------------------------+---------------+--------------+--------------+-------------+
        |                        |Observation Dim| Reset Time   |  Step Time   |  Infer Time |
        +========================+===============+==============+==============+=============+
        |       Small Env        |      64       |     0.1      |     0.005    |     0.004   |
        +------------------------+---------------+--------------+--------------+-------------+
        |      Middle Env        |      300      |     0.5      |     0.01     |     0.008   |
        +------------------------+---------------+--------------+--------------+-------------+
        |         Big Env        |      3000     |       2      |      0.1     |     0.02    |
        +------------------------+---------------+--------------+--------------+-------------+

    
        其中，Observation Dim 是状态维度，Reset Time 是环境 reset 所需的时间，Step Time 是环境 step 一步所需的时间，Infer Time 是 Collector 内部 policy inference 的时间，由于其与环境相关，故也放在此处列出。
        以上三个时间均会在原值的 ``[0.4, 1.6]`` 这一倍率范围内随机浮动，该扰动服从平均分布。
    
    我们设定一个 collector 会在环境管理器中开启 **8** 个环境。对于环境管理器的参数 ``wait_num``，我们设定 sync 需要等待全部 **8** 个环境，而 async 需要等待 **7** 个环境；对于参数 ``timeout``，由于 nerveX 和 tianshou 的 async 的实现逻辑不同，我们分别保留了两者的默认值。

        +------------------------+---------------+--------------------+
        |                        |    Wait Num   |    Timeout         |
        +========================+===============+====================+
        |         Sync           |      8        |     None           |
        +------------------------+---------------+--------------------+
        |         Async          |      7        | 0.01(nx) / None(ts)|
        +------------------------+---------------+--------------------+

        nerveX 和 tianshou 两个框架中，sync 和 async 的 env manager 组成四个待测试的组件，分别简写为 **nx-sync, nx-async, ts-sync, ts-async** 。此外，我们还添加了 nervex 中的 base 环境管理器用作 baseline，简写为 **nx-base** 。
    
    我们设定一次实验中会模拟 **300** 次 collect 过程，每次 collect 需要收集至少 **80** 个训练样本（由于设定 nstep=1，所以可认为是与环境总共交互 80 次）。重复 **3** 次实验取平均。实验开始前跑了一个纯 cpu 任务，该任务可以保证 cpu 负载稳定保持在 60% 左右，模拟真实场景。

- 实验结果

    测速结果如下表所示：（单位：秒）

        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |                        |    ts-async   |   ts-sync    |    nx-base   |   nx-async  |   nx-sync   |
        +========================+===============+==============+==============+=============+=============+
        |       Small Env        |  49.54+0.35   |  44.63+0.09  | 157.70+0.30  | 47.60+0.62  | 47.19+1.13  |
        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |      Middle Env        |  93.02+0.09   |  88.70+0.14  | 311.88+0.22  | 90.84+0.67  | 82.73+1.51  |
        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |         Big Env        | 545.07+1.55   | 520.52+0.30  | 2592.77+0.25 | 519.05+1.05 | 467.50+2.18 |
        +------------------------+---------------+--------------+--------------+-------------+-------------+

        可以发现：
        
            1. nerveX subprocess collector 的速度是 base collector 的 3 至 5 倍左右
            2. 对比 nerveX 与 tianshou 的 sync collector 和 async collecotr，除了在 small env 上 nervex sync collecotor 略慢于 tianshou sync collector 之外，其余五组 nerveX 均快于 tianshou。
    
    针对 Carla, StarCraft2 这类环境，reset time 可能会非常大，所以我们又做了一组实验，将所有的 reset time 乘以 **5** ，总体用时如下表：（单位：秒）

        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |                        |    ts-async   |   ts-sync    |    nx-base   |   nx-async  |   nx-sync   |
        +========================+===============+==============+==============+=============+=============+
        |       Small Env        |  55.11+0.10   |  45.10+0.08  | 176.55+0.05  | 50.71+0.80  | 50.55+1.39  |
        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |      Middle Env        | 130.49+0.09   | 112.27+0.03  | 407.65+0.14  | 98.49+1.29  | 94.18+1.74  |
        +------------------------+---------------+--------------+--------------+-------------+-------------+
        |         Big Env        | 703.49+0.61   | 577.92+0.30  | 2976.80+0.39 | 555.15+1.90 | 520.31+1.05 |
        +------------------------+---------------+--------------+--------------+-------------+-------------+

        可以发现：tianshou collector 在长 reset time 的环境中性能下降得非常明显，而 nerveX collector 由于使用了 reset 线程来避免程序盲等，使得在长 reset time 环境中也保持了较高的性能。



【-- 以下内容均待更新 --】

概述：
    Collector是为训练学习端提供足够数量和质量数据的模块，但Evaluator也作为一种不存储和传递时间步数据的特殊Collector存在。主要包括三大模块:

        - Collector Controller(数据生成控制器)
        - Communication Collector(通信模块)
        - Env Manager(环境管理器)
        - Model(可理解为模型)


Collector Controller(数据生成控制器)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
概述：
    Collector Controller(以下简称AC), 是Collector部分的管理模块和主入口，需要研究员根据自己的实际需求，继承 ``BaseCollector`` 基类实现相关接口。该模块维护Collector的基本信息和与Coordinator的通信，常驻在某个机器上。

代码结构：
    - ``base_collector_controller``: collector controller基类，定义基础接口方法，主循环可参考 ``run`` 方法。collector以job为工作的基本单位，coordinator设置job内容和所需计算资源。AC得到job后，建立其和model(模型推理)以及env_manager(环境模拟) 之间的联系，并根据job执行执行一个或多个episode。AC会会维护单独的线程定期异步地更新model
      。对于数据，当累积的数据量满足一定要求后（例如一定长度），AC会将这部分数据进行打包发送会coordinator。当某个job全部运行完毕后，AC也会将相应信息返回给coordinator。
    - ``comm`` 通信模块：该部分被隐式地封装，通过python的动态属性机制绑定在AC上，研究员只需在配置文件中指定相应的选项即可，在AC的实现代码中只需调用具体的通信接口，而无需涉及具体的通信过程，如果对具体的通信过程感兴趣，可以详细阅读 ``comm`` 部分的相关代码

功能特性：
    - AC启动后就建立和coordinator之间的通信（维护一个心跳线程），但具体的model资源(GPU)，env资源(CPU)还是由coordinator负责管理，AC根据job进行相应处理，这样支持不同job使用不同的资源。
    - AC对于model的更新是异步的，一般是固定时间间隔进行一次相关信息加载和更新。但对于可能出现的即时更新需求，之后也可提供相应的接口 (TODO)。
    - AC主循环接近标准最基础的RL交互迭代过程，即从环境获得state->模型获得action->环境获得obs_next和reward的迭代，具体的定制化需求可在各接口方法中实现。

      .. image:: rl_iter.png

    - AC使用向量化env(env_manager)和batch inference机制来进行效率优化，故对于数据的打包等操作也在AC中完成。但注意可能存在大量的数据不等长情况（例如向量化运行8个env但各个env的结束时间不同，致使在某些状态下会只有部分env执行交互），这时候需要在打包阶段进行相应处理。
    - AC维护collector相关的各类日志信息。
    - 整个Collector部分一般运行在单机上，各个组件之间一般使用IPC进行通信，之后会研究如果利用单机共享内存来避免多余的数据拷贝(TODO)，即AC中只获得共享内存中数据的引用来进行管理。


Communication Collector(通信模块)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
概述：
    数据通信主要包含三类需求：

        - collector和coordinator的信息通信，包含collector状态更新（心跳线程），job获取，job完成信息返回等
        - model更新，一般是collector从读取相应信息（比如神经网络模型）来更新model
        - 生成数据的发送，数据以trajectory为基本单位，即累积一定长度就进行发送。这里采用metadata和stepdata分离的机制，即将metadata返回coordinator，而将stepdata存入某些数据容器（比如ceph or redis）

    目前支持的通信方式有：
        
        - flask-file_system：即通过flask框架，走网络通信完成collector和coordinator的交互，而大块数据的读取则通过文件系统（现在支持一般的磁盘读取和ceph）


Env Manager(环境管理器)
~~~~~~~~~~~~~~~~~~~~~~~~~
概述：
    env manager是一个向量化的环境管理器，其中同时运行多个相同类型不同配置的环境，实际实现方式包含子进程向量化和伪向量化（循环串行）两种模式，具体可参考 `env_manager_overview <../env_manager/env_manager_overview.html>`_ 。

Model(模型)
~~~~~~~~~~~~~~

概述：
    model作为runtime的算法模型，支持运行时的各种动态功能，具体可参考 `Wrapper Hook Overview <./wrapper_hook_overview.html>`_。
    当其作为collector的一部分时，主要支持batch inference和指定样本id的inference。
