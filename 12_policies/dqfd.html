


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>DQfD &mdash; DI-engine 0.1.0 documentation</title>
  

  <link rel="shortcut icon" href="../_static/images/favicon.ico" />
  
  

  

  
  
  

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="SQIL" href="sqil.html" />
  <link rel="prev" title="ICM" href="icm.html" />
    <link href="../_static/css/style.css" rel="stylesheet" type="text/css">


  
  <script src="../_static/js/modernizr.min.js"></script>
  <script>
    MathJax = {
        chtml: {
            scale: 1,
            minScale: 1,
        },
        svg: {
            scale: 1,
            minScale: 1,
        }
    }
</script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/"
        aria-label="OpenMMLab"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
          <li >
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a
                class="resource-option with-down-arrow">
                OpenDILab
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-engine" target="_blank">
                  <span class="dropdown-title">DI-engine </span>
                  <p>OpenDILab Decision AI Engine</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/LightZero" target="_blank">
                  <span class="dropdown-title">LightZero </span>
                  <p>OpenDILab Decision Monte Carlo Tree Search Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GenerativeRL" target="_blank">
                  <span class="dropdown-title">GenerativeRL </span>
                  <p>OpenDILab Generative AI Framework</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-star" target="_blank">
                  <span class="dropdown-title">DI-star </span>
                  <p>OpenDILab Decision AI in StarCraftII</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-drive" target="_blank">
                  <span class="dropdown-title">DI-drive </span>
                  <p>OpenDILab Auto-driving platform</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/GoBigger" target="_blank">
                  <span class="dropdown-title">GoBigger </span>
                  <p>OpenDILab Multi-Agent Environment</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-smartcross" target="_blank">
                  <span class="dropdown-title">DI-smartcross </span>
                  <p>Decision Intelligence Platform for Traffic Crossing Signal Control</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-treetensor" target="_blank">
                  <span class="dropdown-title">DI-treetensor </span>
                  <p>Tree Nested PyTorch Tensor Lib</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/DI-sheep" target="_blank">
                  <span class="dropdown-title">DI-sheep </span>
                  <p>Deep Reinforcement Learning + 3 Tiles Game</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-model-based-RL" target="_blank">
                  <span class="dropdown-title">awesome-model-based-RL </span>
                  <p>A curated list of awesome model based RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-decision-transformer" target="_blank">
                  <span class="dropdown-title">awesome-decision-transformer </span>
                  <p>A curated list of Decision Transformer resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-exploration-rl" target="_blank">
                  <span class="dropdown-title">awesome-exploration-rl </span>
                  <p>A curated list of awesome exploration RL resources (continually updated)</p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item"
                  href="https://github.com/opendilab/awesome-multi-modal-reinforcement-learning" target="_blank">
                  <span class="dropdown-title">awesome-multi-modal-reinforcement-learning </span>
                  <p>A curated list of Multi-Modal Reinforcement Learning resources (continually updated)</p>
                </a>
              </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
    <div class="pytorch-side-scroll">
      <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <div class="pytorch-left-menu-search">
          

          
          
          
          

          



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../00_intro/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_algo/index.html">RL Algorithm Taxonomy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_system/index.html">System Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_best_practice/index.html">Best Practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_api_doc/index.html">API Doc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_faq/index.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning Tutorial</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../10_concepts/index.html">Introduction to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../11_dizoo/index.html">Learn From DI-zoo</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">RL Algorithms Cheat Sheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13_envs/index.html">RL Env Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../20_spec/index.html">Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../21_code_style/index.html">Code Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../22_test/index.html">Unit Test Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../23_visual/index.html">Diagrams and Visualization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../24_cooperation/index.html">Github Cooperation</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="pytorch-container">
    <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
      <div class="pytorch-breadcrumbs-wrapper">
        















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
            Docs
        </a> &gt;
      </li>

        
          <li><a href="index.html">RL Algorithms Cheat Sheet</a> &gt;</li>
        
      <li>DQfD</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/12_policies/dqfd.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
      </div>

      <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
      <div class="pytorch-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
                
  <section id="dqfd">
<h1>DQfD<a class="headerlink" href="#dqfd" title="Permalink to this heading">¶</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h2>
<p>DQfD was proposed in <a class="reference external" href="https://arxiv.org/abs/1704.03732">Deep Q-learning from Demonstrations</a> by DeepMind, which appeared at AAAI 2018.
It ﬁrst pretrains solely on demonstration data, using a combination of 1-step TD, n-step TD, supervised, and regularization losses so that it has a reasonable policy that is a good starting point for learning in the task. Once it starts interacting with the task, it continues learning by sampling from both its selfgenerated data as well as the demonstration data.
The ratio of both types of data in each mini-batch is automatically controlled by a prioritized-replay mechanism.</p>
<p>DQfD leverages small sets of demonstration data to massively accelerate the learning process and performs better than PDD DQN, RBS, HER and ADET on Atari games.</p>
</section>
<section id="quick-facts">
<h2>Quick Facts<a class="headerlink" href="#quick-facts" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>DQfD is an extension algorithm of DQN.</p></li>
<li><p>Store the demonstrations into an expert replay buffer.</p></li>
<li><p>Pre-train the network with expert demonstrations and accelerate the subsequent RL training process.</p></li>
<li><p>Agent gathers more transitions for new replay buffer (see <a class="reference internal" href="#detail-explanation">detail_explanation</a>). Trains network on mixture of new replay buffer and expert replay buffer.</p></li>
<li><p>Network is trained with special loss function made up of four parts: one-step loss, n-step loss, expert large margin classification loss and L2 regularization.</p></li>
</ol>
</section>
<section id="key-equations-or-key-graphs">
<h2>Key Equations or Key Graphs<a class="headerlink" href="#key-equations-or-key-graphs" title="Permalink to this heading">¶</a></h2>
<p>The DQfD overall loss used to update the network is a combination of all four losses.</p>
<p>Overall Loss:  <span class="math notranslate nohighlight">\(J(Q) = J_{DQ}(Q) + \lambda_1 J_n(Q) + \lambda_2J_E(Q) + \lambda_3 J_{L2}(Q)\)</span></p>
<ul class="simple">
<li><p>one-step loss:  <span class="math notranslate nohighlight">\(J_{DQ}(Q) = (R(s,a) + \gamma Q(s_{t+1}, a_{t+1}^{max}; \theta^{'}) - Q(s,a;\theta))^2\)</span>, where <span class="math notranslate nohighlight">\(a_{t+1}^{max} = argmax_a Q(s_{t+1},a;\theta)\)</span>.</p></li>
<li><p>n-step loss:  <span class="math notranslate nohighlight">\(J_n(Q) = r_t + \gamma r_{t+1} + ... + \gamma^{n-1} r_{t+n-1} + max_a \gamma^n Q(s_{t+n},a)\)</span>.</p></li>
<li><p>large margin classiﬁcation loss: <span class="math notranslate nohighlight">\(J_E(Q) = max_{a \in A}[Q(s,a) + L(a_E,a)] - Q(s,a_E)\)</span>, <span class="math notranslate nohighlight">\(L(a_E,a)\)</span> is a margin function that is 0 when <span class="math notranslate nohighlight">\(a = a_E\)</span> and positive otherwise. This loss forces the values of the other actions to be at least a margin lower than the value of the demonstrator’s action.</p></li>
<li><p>L2 regularization loss: <span class="math notranslate nohighlight">\(J_{L2}(Q)\)</span> help prevent from over-ﬁtting.</p></li>
</ul>
</section>
<section id="pseudo-code">
<h2>Pseudo-code<a class="headerlink" href="#pseudo-code" title="Permalink to this heading">¶</a></h2>
<a class="reference internal image-reference" href="../_images/DQfD.png"><img alt="../_images/DQfD.png" class="align-center" src="../_images/DQfD.png" style="width: 613.0px; height: 713.0px;" /></a>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>In Phase I, the agent just uses the demonstration data, and does not do any exploration. The goal of the pre-training phase is to learn to imitate the demonstrator with a value function that satisﬁes the Bellman equation. During this pre-training phase, the agent samples mini-batches from the demonstration data and updates the network by applying the total loss J(Q).</p></li>
</ul>
</div>
<blockquote id="detail-explanation">
<div><ul class="simple">
<li><p>In Phase II, the agent starts acting on the system, collecting self-generated data, and adding it to its replay buffer. Data is added to the replay buffer until it is full, and then the agent starts overwriting old data in that buffer. However, the agent never over-writes the demonstration data. All the losses are applied to the demonstration data in both phases, while the supervised loss is not applied to self-generated data.</p></li>
</ul>
</div></blockquote>
</section>
<section id="extensions">
<h2>Extensions<a class="headerlink" href="#extensions" title="Permalink to this heading">¶</a></h2>
<p>DeepMind has extended DQfD in several ways. Upon a literature search, it seems like two relevant follow-up works are:</p>
<ul>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.00933">Distributed Prioritized Experience Replay</a></p>
<blockquote>
<div><p>The main idea of this paper is to scale up the experience replay data by having many actors collect experience. Their framework is called <strong>Ape-X</strong>, and they claim that Ape-X DQN achieves a new state of the art performance on Atari games. This paper is not that particularly relevant to DQfD, but we include it here mainly because a follow-up paper (see below) used this technique with DQfD.</p>
</div></blockquote>
</li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1805.11593">Observe and Look Further: Achieving Consistent Performance on Atari</a></p>
<blockquote>
<div><p>This paper proposes the <strong>Ape-X DQfD</strong> algorithm, which as one might expect combines DQfD with the distributed prioritized experience replay algorithm.</p>
</div></blockquote>
</li>
</ul>
</section>
<section id="implementations">
<h2>Implementations<a class="headerlink" href="#implementations" title="Permalink to this heading">¶</a></h2>
<p>The DI-engine implements <a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/ding/policy/dqfd.py">DQfD</a>.</p>
<p>The default config of DQfD Policy is defined as follows:</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ding.policy.dqfd.</span></span><span class="sig-name descname"><span class="pre">DQFDPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">EasyDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_field</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/policy/dqfd.html#DQFDPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Policy class of DQFD algorithm, extended by Double DQN/Dueling DQN/PER/multi-step TD.</p>
</dd>
<dt>Config:</dt><dd><table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Symbol</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Value</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Other(Shape)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>str</p></td>
<td><p>dqn</p></td>
<td><div class="line-block">
<div class="line">RL policy register name, refer to</div>
<div class="line">registry <code class="docutils literal notranslate"><span class="pre">POLICY_REGISTRY</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg is optional,</div>
<div class="line">a placeholder</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cuda</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether to use cuda for network</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This arg can be diff-</div>
<div class="line">erent from modes</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">on_policy</span></code></p></td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether the RL algorithm is on-policy</div>
<div class="line">or off-policy</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">priority</span></code></p></td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether use priority(PER)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Priority sample,</div>
<div class="line">update priority</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">priority_IS</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_weight</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>True</p></td>
<td><div class="line-block">
<div class="line">Whether use Importance Sampling Weight</div>
<div class="line">to correct biased update. If True,</div>
<div class="line">priority must be True.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">discount_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">factor</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.97,
[0.95, 0.999]</p></td>
<td><div class="line-block">
<div class="line">Reward’s future discount factor, aka.</div>
<div class="line">gamma</div>
</div>
</td>
<td><div class="line-block">
<div class="line">May be 1 when sparse</div>
<div class="line">reward env</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nstep</span></code></p></td>
<td><p>int</p></td>
<td><p>10,
[3, 5]</p></td>
<td><div class="line-block">
<div class="line">N-step reward discount sum for target</div>
<div class="line">q_value estimation</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">lambda1</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">multiplicative factor for n-step</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">lambda2</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">multiplicative factor for the</div>
<div class="line">supervised margin loss</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">lambda3</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>1e-5</p></td>
<td><div class="line-block">
<div class="line">L2 loss</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">margin_fn</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.8</p></td>
<td><div class="line-block">
<div class="line">margin function in JE, here we set</div>
<div class="line">this as a constant</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_train_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">iter_k</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>10</p></td>
<td><div class="line-block">
<div class="line">number of pertraining iterations</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.update</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">per_collect</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>3</p></td>
<td><div class="line-block">
<div class="line">How many updates(iterations) to train</div>
<div class="line">after collector’s one collection. Only</div>
<div class="line">valid in serial training</div>
</div>
</td>
<td><div class="line-block">
<div class="line">This args can be vary</div>
<div class="line">from envs. Bigger val</div>
<div class="line">means more off-policy</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.batch_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">size</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>64</p></td>
<td><div class="line-block">
<div class="line">The number of samples of an iteration</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.learning</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_rate</span></code></div>
</div>
</td>
<td><p>float</p></td>
<td><p>0.001</p></td>
<td><div class="line-block">
<div class="line">Gradient step length of an iteration.</div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p>16</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.target_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">update_freq</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>100</p></td>
<td><div class="line-block">
<div class="line">Frequency of target network update.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Hard(assign) update</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>17</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">learn.ignore_</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">done</span></code></div>
</div>
</td>
<td><p>bool</p></td>
<td><p>False</p></td>
<td><div class="line-block">
<div class="line">Whether ignore done for target value</div>
<div class="line">calculation.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">Enable it for some</div>
<div class="line">fake termination env</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>18</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">collect.n_sample</span></code></p></td>
<td><p>int</p></td>
<td><p>[8, 128]</p></td>
<td><div class="line-block">
<div class="line">The number of training samples of a</div>
<div class="line">call of collector.</div>
</div>
</td>
<td><div class="line-block">
<div class="line">It varies from</div>
<div class="line">different envs</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>19</p></td>
<td><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">collect.unroll</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">_len</span></code></div>
</div>
</td>
<td><p>int</p></td>
<td><p>1</p></td>
<td><div class="line-block">
<div class="line">unroll length of an iteration</div>
</div>
</td>
<td><div class="line-block">
<div class="line">In RNN, unroll_len&gt;1</div>
</div>
</td>
</tr>
</tbody>
</table>
</dd>
</dl>
</dd></dl>

<p>The network interface DQfD used is defined as follows:</p>
<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ding.model.template.q_learning.</span></span><span class="sig-name descname"><span class="pre">DQN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">SequenceType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">SequenceType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_hidden_size_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">SequenceType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[128,</span> <span class="pre">128,</span> <span class="pre">64]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dueling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_layer_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ReLU()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ding/model/template/q_learning.html#DQN"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The neural nework structure and computation graph of Deep Q Network (DQN) algorithm, which is the most classic         value-based RL algorithm for discrete action. The DQN is composed of two parts: <code class="docutils literal notranslate"><span class="pre">encoder</span></code> and <code class="docutils literal notranslate"><span class="pre">head</span></code>.         The <code class="docutils literal notranslate"><span class="pre">encoder</span></code> is used to extract the feature from various observation, and the <code class="docutils literal notranslate"><span class="pre">head</span></code> is used to compute         the Q value of each action dimension.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code>.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Current <code class="docutils literal notranslate"><span class="pre">DQN</span></code> supports two types of encoder: <code class="docutils literal notranslate"><span class="pre">FCEncoder</span></code> and <code class="docutils literal notranslate"><span class="pre">ConvEncoder</span></code>, two types of head:         <code class="docutils literal notranslate"><span class="pre">DiscreteHead</span></code> and <code class="docutils literal notranslate"><span class="pre">DuelingHead</span></code>. You can customize your own encoder or head by inheriting this class.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">SequenceType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">SequenceType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder_hidden_size_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">SequenceType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[128,</span> <span class="pre">128,</span> <span class="pre">64]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dueling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_hidden_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">head_layer_num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ReLU()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noise</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/ding/model/template/q_learning.html#DQN.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>initialize the DQN (encoder + head) Model according to corresponding input arguments.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>obs_shape (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">SequenceType]</span></code>): Observation space shape, such as 8 or [4, 84, 84].</p></li>
<li><p>action_shape (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">SequenceType]</span></code>): Action space shape, such as 6 or [2, 3, 3].</p></li>
<li><p>encoder_hidden_size_list (<code class="xref py py-obj docutils literal notranslate"><span class="pre">SequenceType</span></code>): Collection of <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> to pass to <code class="docutils literal notranslate"><span class="pre">Encoder</span></code>,                 the last element must match <code class="docutils literal notranslate"><span class="pre">head_hidden_size</span></code>.</p></li>
<li><p>dueling (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[bool]</span></code>): Whether choose <code class="docutils literal notranslate"><span class="pre">DuelingHead</span></code> or <code class="docutils literal notranslate"><span class="pre">DiscreteHead</span> <span class="pre">(default)</span></code>.</p></li>
<li><p>head_hidden_size (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[int]</span></code>): The <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> of head network, defaults to None,                 then it will be set to the last element of <code class="docutils literal notranslate"><span class="pre">encoder_hidden_size_list</span></code>.</p></li>
<li><p>head_layer_num (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>): The number of layers used in the head network to compute Q value output.</p></li>
<li><p>activation (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[nn.Module]</span></code>): The type of activation function in networks                 if <code class="docutils literal notranslate"><span class="pre">None</span></code> then default set it to <code class="docutils literal notranslate"><span class="pre">nn.ReLU()</span></code>.</p></li>
<li><p>norm_type (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[str]</span></code>): The type of normalization in networks, see                 <code class="docutils literal notranslate"><span class="pre">ding.torch_utils.fc_block</span></code> for more details. you can choose one of [‘BN’, ‘IN’, ‘SyncBN’, ‘LN’]</p></li>
<li><p>dropout (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[float]</span></code>): The dropout rate of the dropout layer.                 if <code class="docutils literal notranslate"><span class="pre">None</span></code> then default disable dropout layer.</p></li>
<li><p>init_bias (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Optional[float]</span></code>): The initial value of the last layer bias in the head network.             - noise (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>): Whether to use <code class="docutils literal notranslate"><span class="pre">NoiseLinearLayer</span></code> as <code class="docutils literal notranslate"><span class="pre">layer_fn</span></code> to boost exploration in                 Q networks’ MLP. Default to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span></span></span><a class="reference internal" href="../_modules/ding/model/template/q_learning.html#DQN.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>DQN forward computation graph, input observation tensor to predict q_value.</p>
</dd>
<dt>Arguments:</dt><dd><ul class="simple">
<li><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): The input observation tensor data.</p></li>
</ul>
</dd>
<dt>Returns:</dt><dd><ul class="simple">
<li><p>outputs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Dict</span></code>): The output of DQN’s forward, including q_value.</p></li>
</ul>
</dd>
<dt>ReturnsKeys:</dt><dd><ul class="simple">
<li><p>logit (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): Discrete Q-value output of each possible action dimension.</p></li>
</ul>
</dd>
<dt>Shapes:</dt><dd><ul class="simple">
<li><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): <span class="math notranslate nohighlight">\((B, N)\)</span>, where B is batch size and N is <code class="docutils literal notranslate"><span class="pre">obs_shape</span></code></p></li>
<li><p>logit (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): <span class="math notranslate nohighlight">\((B, M)\)</span>, where B is batch size and M is <code class="docutils literal notranslate"><span class="pre">action_shape</span></code></p></li>
</ul>
</dd>
<dt>Examples:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>  <span class="c1"># arguments: &#39;obs_shape&#39; and &#39;action_shape&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;logit&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
</pre></div>
</div>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For consistency and compatibility, we name all the outputs of the network which are related to action             selections as <code class="docutils literal notranslate"><span class="pre">logit</span></code>.</p>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="benchmark">
<h2>Benchmark<a class="headerlink" href="#benchmark" title="Permalink to this heading">¶</a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>environment</p></th>
<th class="head"><p>best mean reward</p></th>
<th class="head"><p>evaluation results</p></th>
<th class="head"><p>config link</p></th>
<th class="head"><p>comparison</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Pong
(PongNoFrameskip-v4)</p></td>
<td><p>20</p></td>
<td><img alt="../_images/dqfd_pong.png" src="../_images/dqfd_pong.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/atari/config/serial/pong/pong_dqfd_config.py">config_link_p</a></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Qbert
(QbertNoFrameskip-v4)</p></td>
<td><p>4976</p></td>
<td><img alt="../_images/dqfd_qbert.png" src="../_images/dqfd_qbert.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/atari/config/serial/qbert/qbert_dqfd_config.py">config_link_q</a></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>SpaceInvaders
(SpaceInvadersNoFrame
skip-v4)</p></td>
<td><p>1969</p></td>
<td><img alt="../_images/dqfd_spaceinvaders.png" src="../_images/dqfd_spaceinvaders.png" />
</td>
<td><p><a class="reference external" href="https://github.com/opendilab/DI-engine/blob/main/dizoo/atari/config/serial/spaceinvaders/spaceinvaders_dqfd_config.py">config_link_s</a></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Hester T, Vecerik M, Pietquin O, et al. Deep q-learning from demonstrations[C]//Thirty-second AAAI conference on artificial intelligence. 2018.</p></li>
<li><p>Blog:  <a class="reference external" href="https://danieltakeshi.github.io/2019/04/30/il-and-rl/">Combining Imitation Learning and Reinforcement Learning Using DQfD</a></p></li>
</ul>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
  <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
    
    <a href="sqil.html" class="btn btn-neutral float-right" title="SQIL" accesskey="n"
      rel="next">Next <img src="../_static/images/chevron-right-blue.svg"
        class="next-page"></a>
    
    
    <a href="icm.html" class="btn btn-neutral" title="ICM" accesskey="p"
      rel="prev"><img src="../_static/images/chevron-right-blue.svg" class="previous-page"> Previous</a>
    
  </div>
  

  <hr>

  <div role="contentinfo">
    <p>
      &copy; Copyright 2021, OpenDILab Contributors.

    </p>
  </div>
  
  <div>
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a
      href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the
      Docs</a>.
  </div>
   

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">DQfD</a><ul>
<li><a class="reference internal" href="#overview">Overview</a></li>
<li><a class="reference internal" href="#quick-facts">Quick Facts</a></li>
<li><a class="reference internal" href="#key-equations-or-key-graphs">Key Equations or Key Graphs</a></li>
<li><a class="reference internal" href="#pseudo-code">Pseudo-code</a></li>
<li><a class="reference internal" href="#extensions">Extensions</a></li>
<li><a class="reference internal" href="#implementations">Implementations</a></li>
<li><a class="reference internal" href="#benchmark">Benchmark</a></li>
<li><a class="reference internal" href="#reference">Reference</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  


  

  
  <script type="text/javascript" id="documentation_options" data-url_root="../"
    src="../_static/documentation_options.js"></script>
  <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
  <script src="../_static/doctools.js"></script>
  <script src="../_static/sphinx_highlight.js"></script>
  <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  </div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://di-engine-docs.readthedocs.io/en/latest/" aria-label="OpenMMLab"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://github.com/opendilab/DI-engine" target="_blank">GitHub</a>
          </li>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>