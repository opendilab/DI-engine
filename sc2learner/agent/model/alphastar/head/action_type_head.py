'''
Copyright 2020 Sensetime X-lab. All Rights Reserved

Main Function:
    1. Implementation for action_type_head, including basic processes.
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
from sc2learner.torch_utils import build_activation, ResFCBlock, fc_block, one_hot
from sc2learner.torch_utils import CategoricalPdPytorch
from pysc2.lib.static_data import PART_ACTIONS_MAP_INV


class ActionTypeHead(nn.Module):
    r"""
        Overview:
            The action type head uses lstm_output and scalar_context to get
            action_type_logits, action_type and its autoregressive_embedding.
        Interface:
            __init__, forward
    """
    def __init__(self, cfg):
        r"""
            Overview:
                initialize action type architecture
            Arguments:
                - cfg (:obj:`dict`): action type head architecture definition
        """
        super(ActionTypeHead, self).__init__()
        self.cfg = cfg
        self.act = build_activation(cfg.activation)  # use relu as default
        self.project = fc_block(cfg.input_dim, cfg.res_dim, activation=self.act, norm_type=cfg.norm_type)
        blocks = [ResFCBlock(cfg.res_dim, cfg.res_dim, self.act, cfg.norm_type) for _ in range(cfg.res_num)]
        self.res = nn.Sequential(*blocks)
        self.action_fc = build_activation('glu')(cfg.res_dim, cfg.action_num, cfg.context_dim)

        self.action_map_fc = fc_block(cfg.action_num, cfg.action_map_dim, activation=self.act, norm_type=None)
        self.pd = CategoricalPdPytorch
        self.glu1 = build_activation('glu')(cfg.action_map_dim, cfg.gate_dim, cfg.context_dim)
        self.glu2 = build_activation('glu')(cfg.input_dim, cfg.gate_dim, cfg.context_dim)
        self.action_num = cfg.action_num

    def forward(self, lstm_output, scalar_context, action_type_mask, temperature=1.0, action_type=None):
        r"""
            Overview:
                This head embeds lstm_output into a 1D tensor of size 256, passes it through 16 ResBlocks
                with layer normalization each of size 256, and applies a ReLU. The output is converted to
                a tensor with one logit for each possible action type through a GLU gated by scalar_context.
                action_type is sampled from these logits using a multinomial with temperature 0.8. Note that
                during supervised learning, action_type will be the ground truth human action type, and
                temperature is 1.0 (and similarly for all other arguments).

                autoregressive_embedding is then generated by first applying a ReLU and linear layer of
                size 256 to the one-hot version of action_type, and projecting it to a 1D tensor of size 1024
                through a GLU gated by scalar_context. That projection is added to another projection of
                lstm_output into a 1D tensor of size 1024 gated by scalar_context to yield autoregressive_embedding.

            Arguments:
                - lstm_output (:obj:`tensor`): The output tensor of the core LSTM
                - scalar_context (:obj:`tensor`): The combination tensor of certain scalar features, include
                  available_actions, cumulative_statistics, beginning_build_order
                - action_type_mask (:obj:`tensor`): boolean value tensor contains available action type
                - temperature (:obj:`float` or None, optional): Sampling temperature for action_type
                - action_type (:obj:`tensor` or None, optional): Action type

            Returns:
                - logits (:obj:`tensor`): Action_type_logits corresponding to the probabilities of taking each action
                - action_type: (:obj:`tensor`): Action_type sampled from the action_type_logits
                - autoregressive_embedding: (:obj:`tensor`): Autoregressive_embedding that combines information from
                  lstm_output and sampled action_type.

            Shapes:
                - lstm_output: :math:`(B, N_{lstm})` where :math:`N_{lstm}` is the output dim of the core lstm
                - scalar_context: :math:`(B, N_{context})`
                - action_type_mask: :math:`(B, N_{action})` where :math:`N_{action}` is the dim of the whole action
                  space, default is 327
                - action_type: :math:`(B,)`
                - logits: :math:`(B, N_{action})`
                - autoregressive_embedding: :math:`(B, N_{embedding})`
        """

        x = self.project(lstm_output)  # embeds lstm_output into a 1D tensor of size of res_dim, use 256 as default
        x = self.res(x)  # passes x through 16 ResBlocks with layer normalization and ReLU
        x = self.action_fc(x, scalar_context)  # fc for action type without normalization
        # TODO(nyz) show warning info about the masked action_type label
        # action_type_mask is used as inputs in some network parts, so we must detach it from graph
        action_type_mask = action_type_mask.clone().detach()
        if action_type is not None:
            for i, a in enumerate(action_type):
                action_type_mask[i, a.item()] = 1
        if self.cfg.use_mask:
            x -= (1 - action_type_mask) * 1e9
        if action_type is None:
            p = F.softmax(x.div(temperature), dim=1)
            handle = self.pd(p)
            # action_type is sampled from these logits using a multinomial with temperature 0.8.
            # Note that during supervised learning, action_type will be the ground truth human action type,
            # and temperature is 1.0 (and similarly for all other arguments).
            if self.training:
                action_type = handle.sample()
            else:
                action_type = handle.mode()

        # to get autoregressive_embedding
        action_one_hot = one_hot(action_type, self.action_num)  # one-hot version of action_type
        embedding1 = self.action_map_fc(action_one_hot)
        embedding1 = self.glu1(embedding1, scalar_context)
        embedding2 = self.glu2(lstm_output, scalar_context)
        embedding = embedding1 + embedding2

        return x, action_type, embedding
