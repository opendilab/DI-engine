common:
    name: ZvZ
    time_wrapper_type: cuda
data:
    trajectory_len: 64
    trajectory_type: slide_window
    resolution: [128, 128]
train:
    use_cuda: True
    max_epochs: 1000
    batch_size: 2
    learning_rate: 1e-3
    weight_decay: 1e-5
    temperature: 1.0
model:
    policy:
        obs_encoder:
            encoder_names: [scalar_encoder, spatial_encoder, entity_encoder]
            scalar_encoder:
                use_statistics: True  # whether use statistics z
                activation: 'relu'
            spatial_encoder:
                input_dim: 81
                resblock_num: 4
                fc_dim: 256
                project_dim: 32
                downsample_type: 'conv2d'
                down_channels: [64, 128, 128]
                activation: 'relu'
                norm_type: 'BN'
            entity_encoder:
                input_dim: 3037
                head_dim: 128
                hidden_dim: 1024
                output_dim: 256
                head_num: 2
                mlp_num: 2
                layer_num: 3
                dropout_ratio: 0.1
                activation: 'relu'
        scatter:
            input_dim: 256  # entity_encoder.output_dim
            output_dim: 32
        core:
            input_size: 1536  # spatial_encoder.fc_dim + entity_encoder.output_dim + scalar_encoder.output_dim
            hidden_size: 384
            num_layers: 3
        head:
            head_names: [action_type_head, delay_head, queued_head, selected_units_head, target_units_head, location_head]
            action_type_head:
                input_dim: 384  # core.hidden_size
                res_dim: 256
                res_num: 16
                action_num: 563
                action_map_dim: 256
                gate_dim: 1024
                context_dim: 128  # TODO
                activation: 'relu'
                norm_type: 'LN'
            delay_head:
                input_dim: 1024  # action_type_head.gate_dim
                decode_dim: 256
                delay_dim: 128
                delay_map_dim: 256
                activation: 'relu'
            queued_head:
                input_dim: 1024  # action_type_head.gate_dim
                decode_dim: 256
                queued_dim: 2
                queued_map_dim: 256
                activation: 'relu'
            selected_units_head:
                input_dim: 1024  # action_type_head.gate_dim
                entity_embedding_dim: 256  # entity_encoder.output_dim
                key_dim: 32
                unit_type_dim: 259
                func_dim: 256
                hidden_dim: 32
                num_layers: 1
                max_entity_num: 64
                activation: 'relu'
            target_units_head:
                input_dim: 1024  # action_type_head.gate_dim
                entity_embedding_dim: 256  # entity_encoder.output_dim
                key_dim: 32
                unit_type_dim: 259
                func_dim: 256
                hidden_dim: 32
                num_layers: 1
                max_entity_num: 64
                activation: 'relu'
            location_head:
                upsample_type: 'deconv'
                upsample_dims: [128, 64, 16, 1]  # len(upsample_dims)-len(down_channels)+1 = ratio
                res_dim: 128
                res_num: 4
                reshape_size: [16, 16]  
                reshape_channel: 4  # entity_encoder.gate_dim / reshape_size
                map_skip_dim: 128  # spatial_encoder.down_channels[-1]
                activation: 'relu'
logger:
    print_freq: 10
    save_freq: 5000

