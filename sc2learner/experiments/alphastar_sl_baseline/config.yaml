model:
    policy:
        obs_encoder:
            encoder_names: [scalar_encoder, spatial_encoder, entity_encoder]
            scalar_encoder:
                activation: 'relu'
            spatial_encoder:
                input_dim: 40
                resblock_num: 4
                fc_dim: 256
                project_dim: 32
                downsample_type: 'conv2d'
                down_channels: [64, 128, 128]
                activation: 'relu'
                norm_type: 'BN'
            entity_encoder:
                input_dim: 256  # TODO 512
                head_dim: 128
                hidden_dim: 1024
                output_dim: 256
                head_num: 2
                mlp_num: 2
                layer_num: 3
                dropout_ratio: 0.1
                activation: 'relu'
        scatter:
            input_dim: 256  # entity_encoder.output_dim
            output_dim: 32
        core:
            input_size: 1152  # spatial_encoder.fc_dim + entity_encoder.output_dim + scalar_encoder.output_dim
            hidden_size: 384
            num_layers: 3
        head:
            head_names: [action_type_head, delay_head, queued_head, selected_units_head, target_units_head, location_head]
            action_type_head:
                input_dim: 384  # core.hidden_size
                res_dim: 256
                res_num: 16
                action_num: 314  # TODO
                gate_dim: 1024
                context_dim: 120  # TODO
                activation: 'relu'
                norm_type: 'LN'
            delay_head:
                input_dim: 1024  # action_type_head.gate_dim
                decode_dim: 256
                delay_dim: 128
                delay_map_dim: 256
                activation: 'relu'
            queued_head:
                input_dim: 1024  # action_type_head.gate_dim
                decode_dim: 256
                queued_dim: 2
                queued_map_dim: 256
                activation: 'relu'
            selected_units_head:
                input_dim: 1024  # action_type_head.gate_dim
                entity_embedding_dim: 256  # entity_encoder.output_dim
                key_dim: 32
                unit_type_dim: 47  # TODO
                func_dim: 256
                hidden_dim: 32
                num_layers: 1
                max_entity_num: 64
                activation: 'relu'
            target_units_head:
                input_dim: 1024  # action_type_head.gate_dim
                entity_embedding_dim: 256  # entity_encoder.output_dim
                key_dim: 32
                unit_type_dim: 47  # TODO
                func_dim: 256
                hidden_dim: 32
                num_layers: 1
                max_entity_num: 64
                activation: 'relu'
            location_head:
                upsample_type: 'deconv'
                upsample_dims: [128, 64, 16, 1]
                res_dim: 128
                res_num: 4
                reshape_size: [16, 16]  
                reshape_channel: 4  # entity_encoder.gate_dim / reshape_size
                map_skip_dim: 128  # spatial_encoder.down_channels[-1]
                activation: 'relu'
    value:
