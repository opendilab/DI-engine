common:
    name: ZergStat
    time_wrapper_type: cuda
env:
   screen_resolution: 128  # not used
   default_step_mul: 8  # not used
   game_steps_per_episode: 43200
   disable_fog: False
   realtime: False
   crop_map_to_playable_area: False
   map_name: 'KairosJunction'
   use_available_action_transform: True
   use_stat: True
   obs_stat_type: 'self_online'  # self_online, replay_online, replay_last
   beginning_build_order_num: 20
model:
    use_value_network: True
train:
    #batch_size: 64
    trajectory_len: 64
    temperature: 0.8
    use_cuda: True
    use_distributed: True
    max_iterations: 1e9
logger:
    print_freq: 10
    save_freq: 200
    eval_freq: 200
    var_record_type: 'alphastar'
league:
    race: ['zerg']
    active_players:
        main_player: 1
        main_exploiter: 0
        league_exploiter: 0
actor:
    use_cuda: False
    heartbeats_freq: 120
    heartbeats_thread: True
manager:
    # not used at the moment
coordinator:
    use_fake_data: False
replay_buffer:
    meta_maxlen: 4096
    max_reuse: 2
    min_sample_ratio: 2
    alpha: 0.6
    beta: 0.5
    cache_maxlen: 64
    timeout: 8  # times of the seconds of per learning iteration
    
# values in this section is mean to be shared by multiple components
system:
    learner_port: 18193               # learner port
    learner_uid:              # uid could be set, used with re_register and an existed uid should be set
    learner_re_register:          # if reregister learner, choices in [True, False], False as default
    learner_heartbeats_thread: False  # if use thread to send heartbeats to coordinator in learner
    learner_heartbeats_freq: 10       # send heartbeats each `freq`
    coordinator_ip: 10.5.36.31        # learner and coordinator are in same cluster
    coordinator_port: 18194
    coordinator_check_dead_learner_freq: 300
    # manager_ip can be set to 'auto' or the real IP of the manager instance
    # this value is used by actors to find what they should connect and report to
    # if it's set to 'auto', the manager node of the Slurm cluster will be used as the manager
    manager_ip: 10.5.36.31 #'auto'
    manager_port: 18195
    league_manager_port: 18196
    auto_run_actor: False
    use_partitions: ['x_cerebra']  #['VI_SP_Y_V100_A', 'VI_SP_Y_V100_B']
    actor_num: [2, 2]
    use_ceph: True  # TODO: there is no support for lustre file on the actor side
    # The paths must end with a /
    ceph_traj_path: 's3://alphastar_fake_data/'
    ceph_model_path: 's3://alphastar_fake_data/'
    ceph_stat_path: 's3://alphastar_fake_data/'
