env:
    use_cuda: False
    screen_resolution: [128, 128]
    default_step_mul: 8  # not used
    game_steps_per_episode: 30
    disable_fog: False
    realtime: False  # realtime mode, incompatible with action_delays
    use_stat: True
    beginning_build_order_num: 20
    use_global_cumulative_stat: True
    use_available_action_transform: True
    temperature: 1.0
    crop_map_to_playable_area: False
    action_delays: [0.5, 0.25, 0.25]  # list of probablities of delay from 1 to n or null for delay=1
    compress_obs: 'simple'
model:
    action_type: fixed
# for testing actor worker
actor:
    manager_ip: 'auto'
    manager_port: 18295
    heartbeats_freq: 10
    max_connection_retries: 20
    # The paths must end with a /
    ceph_traj_path: 's3://alphastar_fake_data/'
    ceph_model_path: 's3://alphastar_fake_data/'
    ceph_stat_path: 's3://alphastar_fake_data/'

api:
    learner_port: 18293               # learner port
    coordinator_ip: 10.198.6.31       # learner and coordinator are in same cluster
    coordinator_port: 18294
    manager_ip: 10.198.6.31           # can be on any cluster
    manager_port: 18295
    ceph_path: s3://alphastar_fake_data/
    actor:
        heartbeats_thread: True
    manager:
        auto_run_actor: False
        use_partitions: ['VI_SP_Y_V100_A', 'VI_SP_Y_V100_B']
        actor_num: [2, 2]
    coordinator:
        use_fake_data: True
        fake_model_path: do_not_load
        fake_stat_path: do_not_load

replay_buffer:
    meta_maxlen: 4096
    max_reuse: 2
    min_sample_ratio: 2
    alpha: 0.6
    beta: 0.5
    cache_maxlen: 2
    timeout: 8  # times of the seconds of per learning iteration