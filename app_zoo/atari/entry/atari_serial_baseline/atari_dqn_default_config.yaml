common:
    name: AtariConfig
    time_wrapper_type: cuda
    save_path: '.'
    load_path: ''
    algo_type: 'dqn'
learner:
    use_cuda: False
    use_distributed: False
    max_iterations: 10000000
    train_step: 1000
    learning_rate: 0.0001
    weight_decay: 0.0
    eps:
        type: 'linear'
        start: 1.
        end: 0.005
        decay: 100000
    data:
        batch_size: 64
        max_reuse: 8
        buffer_length: 100000
    dqn:
        discount_factor: 0.99
        is_double: True
        dueling: True
    hook:
        save_ckpt_after_iter:
            name: save_ckpt_after_iter
            type: save_ckpt
            priority: 40
            position: after_iter
            ext_args:
                freq: 100000
        log_show:
            name: log_show
            type: log_show
            priority: 20
            position: after_iter
            ext_args:
                freq: 1000
actor:
    env_num: 16
    episode_num: 8
    print_freq: 1000
evaluator:
    env_num: 4
    episode_num: 1
    eval_step: 10000
    stop_val: 20  # pong: 20
env:
    env_id: 'PongNoFrameskip-v4'
    frame_stack: 4
    is_train: True
