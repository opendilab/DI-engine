common:
    name: CartpoleR2D2Config
    save_path: '.'
    load_path: ''
env:
    env_manager_type: 'base'  # [base, subprocess]
    import_names: ['app_zoo.classic_control.cartpole.envs.cartpole_env']
    env_type: 'cartpole'
    actor_env_num: 8
    evaluator_env_num: 5
policy:
    use_cuda: False
    policy_type: 'r2d2'
    import_names: ['nervex.policy.r2d2']
    on_policy: False
    model:
        obs_dim: 4
        action_dim: 2
        embedding_dim: 32
    learn:
        train_step: 1
        batch_size: 64
        learning_rate: 0.001
        weight_decay: 0.0
        algo:
            target_update_freq: 200
            discount_factor: 0.99
            burnin_step: 2
            nstep: 2
            use_value_rescale: True
    collect:
        traj_len: 14  # (2*unroll_len + nstep)
        unroll_len: 6  # (2*nstep + burnin_step)
        env_num: 8  # actor_env_num
        algo:
            burnin_step: 2
            nstep: 2
    eval:
        env_num: 5  # evaluator_env_num
    command:
        eps:
            type: 'exp'
            start: 0.95
            end: 0.05
            decay: 10000
replay_buffer:
    buffer_name: ['agent']
    agent:
        meta_maxlen: 5000
        max_reuse: 10
        min_sample_ratio: 1
actor:
    n_sample: 32
    traj_len: 14
    traj_print_freq: 100
    collect_print_freq: 100
evaluator:
    n_episode: 5
    eval_freq: 200
    stop_val: 195
learner:
    hook:
        log_show:
            name: log_show
            type: log_show
            priority: 20
            position: after_iter
            ext_args:
                freq: 100
command:
    placeholder: 'placeholder'
