common:
    name: PendulumDdpgConfig
    save_path: '.'
    load_path: ''
env:
    env_manager_type: 'base'  # [base, subprocess]
    import_names: ['app_zoo.classic_control.pendulum.envs.pendulum_env']
    env_type: 'pendulum'
    actor_env_num: 8
    evaluator_env_num: 8
    use_act_scale: True
policy:
    use_cuda: False
    policy_type: 'sac'
    import_names: ['nervex.policy.sac']
    on_policy: False
    model:
        obs_dim: 3
        action_dim: 1
        use_twin_q: True
    learn:
        train_step: 1
        batch_size: 128
        learning_rate_q: 0.003
        learning_rate_value: 0.003
        learning_rate_policy: 0.003
        learning_rate_alpha: 0.003
        weight_decay: 0.0001
        ignore_done: True
        algo:
            target_theta: 0.005
            discount_factor: 0.99
            use_twin_q: True
            alpha: 0.2
            reparameterization: True
            policy_std_reg_weight: 0.001
            policy_mean_reg_weight: 0.001
            is_auto_alpha: True
    collect:
        traj_len: 1
        unroll_len: 1
        algo:
            noise_sigma: 0.1
    command:
        placeholder: 'placeholder'
replay_buffer:
    buffer_name: ['agent']
    agent:
        meta_maxlen: 30000
        max_reuse: 1024
        min_sample_ratio: 1
actor:
    n_sample: 8
    traj_len: 1
    traj_print_freq: 1000
    collect_print_freq: 1000
evaluator:
    n_episode: 8
    eval_freq: 500
    stop_val: -250
learner:
    hook:
        log_show:
            name: log_show
            type: log_show
            priority: 20
            position: after_iter
            ext_args:
                freq: 500
command:
    placeholder: 'placeholder'
