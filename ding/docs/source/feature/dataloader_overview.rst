DataLoader Overview
=====================


Introduction
^^^^^^^^^^^^^^^^^^^^

概述：
    参照 PyTorch 中的 DataLoader ，我们结合 **从硬盘读取训练数据至内存** 的实际需求，设计了 **异步式数据加载器** 。
    
    AsyncDataLoader 支持将训练数据读取任务分割为多个子任务交由 **多进程** 执行，大大缩短了 I/O 时间。
    
    AsyncDataLoader 包含以下进程或线程：
        - ``get_data_thread`` 线程：获取数据读取任务，并将其发送给 ``async_process`` 进程。
        - ``cuda_thread`` 线程：若指定需要 GPU 数据，则在该线程中将数据从 CPU 搬运至 GPU。
        - ``async_process`` 进程：若 num_workers=0，则该进程负责执行所有的数据读取任务；否则，将数据读取任务根据 ``chunk_size`` 分为多个子任务，并放置在 ``job_queue`` 中。
        - ``worker`` 进程列表：包含多个 worker 进程，每个 worker 进程都从 ``job_queue`` 中获取数据读取任务并执行。

数据加载流程：
    .. note::

            AsyncDataLoader 是异步加载数据的，即同一时刻各进程、线程均在工作。
            以下流程可以理解为一条数据从磁盘文件到 learner 端用于训练之间所经历的过程。
    
    1. ``async_process`` 通过管道向 ``get_data_thread`` 发送“获取数据”请求，进入流程2。
    2. ``get_data_thread`` 从 ``data_source`` 处获取到数据或数据任务。若为数据，则直接放置在 ``async_train_queue`` （该情况并不主要讨论，也并非 AsyncDataLoader 的设计初衷），直接进入流程5；否则将其通过管道发回给 ``async_process`` ，进入流程3。
    3. ``async_process`` 判断 ``num_workers`` 的大小：若为0或1表明不使用多进程（ ``__init__`` 中 ``worker`` 进程列表也不会被初始化），直接在本进程中读取数据，并将读取到的数据放置在 ``async_train_queue`` ，直接进入流程5；若为大于1的数则表明使用多进程，本进程仅负责将数据读取任务切分成 ``batch_size`` / ``chunk_size`` 块，并放置在 ``job_queue`` 中，进入流程4。
    4. ``worker`` 进程列表中的每一个元素 ``worker_process`` 从 ``job_queue`` 中获取一个数据读取任务并执行，读出的数据按照原来的 batch 进行存储及连接。由于 需要保证batch 之间的顺序，所以只有当上一个 batch 的数据全部被读出，上一个 batch 的数据放入 ``async_train_queue`` 后，才可以将下一个 batch 的数据放入 ``async_train_queue`` ，否则即使数据读取连接完毕，也必须等待。然后进入流程5.
    5. 若指定需要 GPU 数据，则 ``cuda_thread`` 将 ``async_train_queue`` 中的数据从 CPU 搬运至 GPU，并存储在 ``cuda_queue`` 。


Profile Experiment 测速实验
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

我们将 AsyncDataLoader 与 PyTorch 中的 DataLoader （以下简称 TorchDataLoader ）进行了速度上的对比。结果表明，在各种规模的环境下、以及各种数据流压力下， AsyncDataLoader 都比 TorchDataLoader 有较明显的效率优势，且随着环境规模与数据流压力的增大，优势更加明显。

- 实验准备

    我们准备了四个规模不同的环境，轨迹数据文件大小也各不相同：

        - Small Env (4.5KB)，Atari's Pong 规模
        - Middle Env (40KB)
        - Big16 Env (16MB)
        - Big64 Env (64MB)，星际规模
    
    环境相应参数如下表：

        +------------------------+-------------+--------------+--------------+-------------+
        |                        |  File Time  | Process Time |  Batch Size  |  Chunk Size |
        +========================+=============+==============+==============+=============+
        |       Small Env        |    0.0008   |     0.005    |     128      |     32      |
        +------------------------+-------------+--------------+--------------+-------------+
        |      Middle Env        |    0.0008   |     0.05     |      64      |     16      |
        +------------------------+-------------+--------------+--------------+-------------+
        |       Big16 Env        |    0.6      |     0.2      |       4      |      1      |
        +------------------------+-------------+--------------+--------------+-------------+
        |       Big64 Env        |    2        |     0.35     |       4      |      1      |
        +------------------------+-------------+--------------+--------------+-------------+
    
        其中，File Time 指将数据从文件中读取到内存的时间， Process Time 指数据预处理时间，这两个时间均为多次重复实验测得。Batch Size 为一批数据数量， Chunk Size 为将一批数据分割开后的一块数据数量，是 AsyncDataLoader 的一个参数。
    
    我们还设定了三个 数据处理（ DataLoader 读取并预处理数据）时间 / 数据推断（模型利用数据）时间 这一比例，用于模拟 DataLoader 的不同工作负载；也可以理解为，当数据不变时，网络规模递减（意味着数据推断时间递减）时， DataLoader 应对越来越密集的数据需求的能力。
    分别为：

        - Slow Dataflow, ratio=1.
        - Middle Dataflow, ratio=2. 
        - Fast Dataflow, ratio=3.
    
    一次实验包括50次数据处理+推断过程，即50次迭代，忽略前5次时间表现不太稳定的迭代，取后45次的平均值作为单次实验结果。实验重复10次取平均值。
    实验中 ``num_workers`` 设为8，使用GPU进行数据推断。

- 实验结果

    我们测量了三种 DataLoader ，分别是：

        - TorchDataLoader, num_workers=0，即不使用多进程，以作为baseline。以下简称 TorchDataLoader-base
        - TorchDataLoader, num_workers=8，即和 AsyncDataLoader 使用相同的进程数。以下简称 TorchDataLoader-8
        - 我们实现的 AsyncDataLoader
        
    也将按照从上至下的顺序展示三个 DataLoader 的测速结果。

    首先是整体流程所用全部时间（单位：秒）：

        +------------------------+-----------------+-----------------+-----------------+
        |                        |  Slow Dataflow  | Middle Dataflow |  Fast Dataflow  |
        +========================+=================+=================+=================+
        |                        |  36.62          |  34.00          |  32.82          |
        |                        +-----------------+-----------------+-----------------+
        |       Small Env        |   5.41          |   4.52          |   4.26          |
        |                        +-----------------+-----------------+-----------------+
        |                        |   4.36          |   4.49          |   4.15          |
        +------------------------+-----------------+-----------------+-----------------+
        |                        | 162.40          | 153.50          | 149.20          |
        |                        +-----------------+-----------------+-----------------+
        |      Middle Env        |  19.36          |  18.64          |  19.05          |
        |                        +-----------------+-----------------+-----------------+
        |                        |  18.80          |  18.51          |  18.39          |
        +------------------------+-----------------+-----------------+-----------------+
        |                        | 136.60          | 126.49          | 123.81          |
        |                        +-----------------+-----------------+-----------------+
        |       Big16 Env        |  20.39          |  19.59          |  20.35          |
        |                        +-----------------+-----------------+-----------------+
        |                        |  18.76          |   9.26          |   7.70          |
        +------------------------+-----------------+-----------------+-----------------+
        |                        | 329.31          | 296.80          | 276.32          |
        |                        +-----------------+-----------------+-----------------+
        |       Big64 Env        |  72.17          |  67.58          |  70.11          |
        |                        +-----------------+-----------------+-----------------+
        |                        |  52.13          |  26.01          |  19.56          |
        +------------------------+-----------------+-----------------+-----------------+

        （注：由于逐渐增大的数据流压力是通过逐渐降低的 infer time 实现的，所以对于同一环境，数据流压力增大，总用时反而会减小）
    
    然后是在整体流程中，阻塞在 DataLoader ，等待其读取数据、处理数据的时间，所占整体时间的比例：

        +------------------------+-----------------+-----------------+-----------------+
        |                        |  Slow Dataflow  | Middle Dataflow |  Fast Dataflow  |
        +========================+=================+=================+=================+
        |                        |          0.8825 |          0.9365 |          0.9670 |
        |                        +-----------------+-----------------+-----------------+
        |       Small Env        |          0.2044 |          0.5219 |          0.7403 |
        |                        +-----------------+-----------------+-----------------+
        |                        |          0.0067 |          0.5087 |          0.7335 |
        +------------------------+-----------------+-----------------+-----------------+
        |                        |          0.8843 |          0.9381 |          0.9684 |
        |                        +-----------------+-----------------+-----------------+
        |      Middle Env        |          0.0295 |          0.4955 |          0.7530 |
        |                        +-----------------+-----------------+-----------------+
        |                        |          0.0001 |          0.4923 |          0.7441 |
        +------------------------+-----------------+-----------------+-----------------+
        |                        |          0.8645 |          0.9268 |          0.9625 |
        |                        +-----------------+-----------------+-----------------+
        |       Big16 Env        |          0.0927 |          0.5274 |          0.7703 |
        |                        +-----------------+-----------------+-----------------+
        |                        |          0.0001 |          0.0008 |          0.3982 |
        +------------------------+-----------------+-----------------+-----------------+
        |                        |          0.8421 |          0.9124 |          0.9525 |
        |                        +-----------------+-----------------+-----------------+
        |       Big64 Env        |          0.2796 |          0.6127 |          0.8142 |
        |                        +-----------------+-----------------+-----------------+
        |                        |          0.0000 |          0.0001 |          0.3350 |
        +------------------------+-----------------+-----------------+-----------------+

    不难发现，三者的数据读取速度及整体训练效率为： AsyncDataLoader > TorchDataLoader-8 > TorchDataLoader-base。
    且 **当环境规模增大，或是数据流压力增大时， AsyncDataLoader 的优势更加明显** 。

    我们还观察了在 Big64 Env 中， Fast Dataflow 情况下的 **CPU负载** 。我们发现 AsyncDataLoader 确实是提高了 CPU 负载才获得了如此优秀的性能提升： CPU 负载约为 60%，接近 TorchDataLoader-8 的 CPU 负载率20%的三倍，这一点也与其相较于 TorchDataLoader-8 27%的训练时间相吻合。
    同时我们还发现， AsyncDataLoader 的 CPU 负载相对稳定，在60%附近小幅波动；而 TorchDataLoader-8 随时间波动非常大，低至1%，高至50%。